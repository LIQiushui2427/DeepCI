{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d77d2b9-1d2b-4d84-8c0e-2b51d3a546e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 182] 操作系统无法运行 %1。 Error loading \"d:\\ProgramFiles\\anaconda3\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mf:\\DeepCausalInequalities\\AdversarialGMM\\local_notebooks\\final_ADeepCI_singlevar_Experiments.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/DeepCausalInequalities/AdversarialGMM/local_notebooks/final_ADeepCI_singlevar_Experiments.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/DeepCausalInequalities/AdversarialGMM/local_notebooks/final_ADeepCI_singlevar_Experiments.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix, f1_score\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/DeepCausalInequalities/AdversarialGMM/local_notebooks/final_ADeepCI_singlevar_Experiments.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramFiles\\anaconda3\\lib\\site-packages\\torch\\__init__.py:129\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m     err \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mWinError(last_error)\n\u001b[0;32m    128\u001b[0m     err\u001b[39m.\u001b[39mstrerror \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m Error loading \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdll\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m or one of its dependencies.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 129\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    130\u001b[0m \u001b[39melif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     is_loaded \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 182] 操作系统无法运行 %1。 Error loading \"d:\\ProgramFiles\\anaconda3\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "#import \n",
    "\n",
    "seedNum = 888\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seedNum)\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "np.random.seed(seedNum)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import torch\n",
    "\n",
    "#import autokeras as ak\n",
    "#import keras_tuner as kt\n",
    "\n",
    "\n",
    "#load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c249b24-2bc8-4a50-a34c-6b9b1a3e9e9d",
   "metadata": {},
   "source": [
    "# use the normal \"scale\" estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e330df4-e41d-4c1d-8c2c-02698a6d616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_epochs = 60\n",
    "# bs = 2\n",
    "\n",
    "n_epochs = 40 #80\n",
    "bs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7620dd90-5f1b-4d05-a5c9-6d897f03bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 5\n",
    "\n",
    "rho = 0.2\n",
    "\n",
    "func_run = \"sin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8552fff8-2417-4e18-bcdb-f725e23ca923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5dc0866-6082-45f2-b228-629307f360e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function(func_str):\n",
    "    if func_str == \"abs\":\n",
    "        return (lambda x: ((np.abs(np.abs(x)-2)-1.5)/1).flatten(), \n",
    "                lambda x: ((torch.abs(torch.abs(x)-2)-1.5)/1).flatten())\n",
    "    elif func_str == \"log\":\n",
    "        return (lambda x: 2*np.log(np.abs(x)).flatten(), \n",
    "                lambda x: 2*torch.log(torch.abs(x)).flatten())\n",
    "    elif func_str == \"sin\":\n",
    "        return (lambda x: np.sin(x).flatten(), \n",
    "                lambda x: torch.sin(x).flatten())\n",
    "    else:\n",
    "        return (lambda x: np.sign(np.abs(np.abs(x)-5)-2).flatten(), \n",
    "                lambda x: torch.sign(torch.abs(torch.abs(x)-5)-2).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb4ee77-a552-4026-9dac-14abf4b70b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simdata(NUM_I,seed,func,rho): #a = y_train/test, b = X_train/test\n",
    "    \n",
    "    kk = 5\n",
    "    \n",
    "    np.random.seed(seed)    \n",
    "    X_1_a_j = [] \n",
    "    X_2_a_j = [] \n",
    "    X_1_a_k = [] \n",
    "    X_2_a_k = [] \n",
    "    X_1_b_j = [] \n",
    "    X_2_b_j = [] \n",
    "    X_1_b_k = [] \n",
    "    X_2_b_k = []\n",
    "    Z       = []\n",
    "    for i in tqdm(range(0,NUM_I)):\n",
    "        #J = np.random.randint(4,10) # number of choice\n",
    "        \n",
    "        X_1_a = np.random.uniform(-1,1,J) #customer a\n",
    "        X_2_a = np.random.uniform(-kk,kk,J)  #customer a # -3 to 3 work well\n",
    "        X_1_b = np.random.uniform(-1,1,J) #customer b\n",
    "        X_2_b = np.random.uniform(-kk,kk,J) #customer b\n",
    "        \n",
    "        xi  = np.random.normal(0,0.5,J)    # same across all customers\n",
    "        \n",
    "        X_2_a = X_2_a + rho*xi  #customer a endogeneity\n",
    "        \n",
    "        X_2_b = X_2_b + rho*xi  #customer b endogeneity\n",
    "        \n",
    "        u_a   = X_1_a + 2*func(X_2_a) + xi + np.random.normal(0,3,J) # \\epsilon_{a} # originally 0.1\n",
    "        u_b   = X_1_b + 2*func(X_2_b) + xi + np.random.normal(0,3,J) # \\epsilon_{b}\n",
    "        choice_j = np.argmax(u_a) # return the index of product in the sample that customer a chose, we assume customer a as choose j\n",
    "\n",
    "        choice_k = np.argmax(u_b) # return the index of product in the sample that customer b chose, we assume customer b as choose k\n",
    "               \n",
    "        if choice_j == choice_k:\n",
    "            continue\n",
    "        else:  \n",
    "\n",
    "            X_1_a_j.append(X_1_a[choice_j])\n",
    "            X_2_a_j.append(X_2_a[choice_j])\n",
    "            X_1_a_k.append(X_1_a[choice_k])\n",
    "            X_2_a_k.append(X_2_a[choice_k])\n",
    "            \n",
    "            X_1_b_j.append(X_1_b[choice_j]) \n",
    "            X_2_b_j.append(X_2_b[choice_j]) \n",
    "            X_1_b_k.append(X_1_b[choice_k]) \n",
    "            X_2_b_k.append(X_2_b[choice_k]) \n",
    "            Z.append(np.array([X_1_a[choice_j], X_2_a[choice_j], X_1_a[choice_k], X_2_a[choice_k], \n",
    "                                   X_1_b[choice_j], X_2_b[choice_j], X_1_b[choice_k], X_2_b[choice_k]]))\n",
    "    \n",
    "    return torch.Tensor(X_1_a_j).reshape((-1,1)).double(), torch.Tensor(X_2_a_j).reshape((-1,1)).double(), \\\n",
    "torch.Tensor(X_1_a_k).reshape((-1,1)).double(), torch.Tensor(X_2_a_k).reshape((-1,1)).double(), torch.Tensor(X_1_b_j).reshape((-1,1)).double(), \\\n",
    "torch.Tensor(X_2_b_j).reshape((-1,1)).double(), torch.Tensor(X_1_b_k).reshape((-1,1)).double(), torch.Tensor(X_2_b_k).reshape((-1,1)).double(), \\\n",
    "torch.tensor(Z, dtype=torch.float64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ad8027-3000-4929-b8d3-47a42661db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa,bb = get_function(func_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38b07e4-f0c0-4b72-96d6-925250d5953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 30601.22it/s]\n",
      "/tmp/ipykernel_17993/4030718913.py:54: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  torch.tensor(Z, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(19104)\n",
    "X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z = Simdata(10000,2,aa,rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0a0f2d5-b1d7-4b6d-a85d-85b39a1c7681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = (X_1_a_j[0:100]+2*torch.unsqueeze(aa(X_2_a_j[0:100]),-1))-(X_1_a_k[0:100]+2*torch.unsqueeze(aa(X_2_a_k[0:100]),-1))\n",
    "torch.sum(tmp<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b4d8d7-1c6f-4b3f-bb7d-cfcc9124013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/notebooks/AdversarialGMM/local_notebooks', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path\n",
    "print(sys.path)\n",
    "sys.path.append('/notebooks/AdversarialGMM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8f6a60-b62f-4413-9b13-2696b09808af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### module imports\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "### import from our files\n",
    "from mliv.dgps import get_data, get_tau_fn, fn_dict\n",
    "from mliv.neuralnet.utilities import log_metrics, plot_results, hyperparam_grid,\\\n",
    "                                     hyperparam_mult_grid, eval_performance\n",
    "from mliv.neuralnet.mnist_dgps import AbstractMNISTxz\n",
    "from mliv.neuralnet import AGMM,KernelLayerMMDGMM\n",
    "from mliv.neuralnet.rbflayer import gaussian, inverse_multiquadric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884b4136-77ea-4c22-8e12-857fe1d8954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1768071-a988-45df-a18e-13de550552a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a82e63c-963d-4dec-9ace-4f6d403f0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Z_agmm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Z_agmm, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "class CNN_Z_kernel(nn.Module):\n",
    "    def __init__(self, g_features=100):\n",
    "        super(CNN_Z_kernel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, g_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "class CNN_X(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_X, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 1, 28, 28)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e893ec27-77fd-4945-a9ee-f4ae0fb6a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_z_kernel(n_z, n_hidden, g_features, dropout_p):\n",
    "    FC_Z_kernel = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, g_features),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    return FC_Z_kernel\n",
    "\n",
    "\n",
    "def fc_z_agmm(n_z, n_hidden, dropout_p):\n",
    "    FC_Z_agmm = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_Z_agmm\n",
    "\n",
    "\n",
    "def fc_x(n_t, n_hidden, dropout_p):\n",
    "    FC_X = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_t, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aab8430-e3fa-4560-a3da-8e0178dbdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 500\n",
    "n_hidden = 300\n",
    "n_instruments = 1\n",
    "dropout_p = 0.1\n",
    "\n",
    "\n",
    "class CNN_X(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_X, self).__init__()\n",
    "        self.conv1 = nn.Linear(1, k)\n",
    "        self.conv2 = nn.Linear(k, 200)\n",
    "        self.conv3 = nn.Linear(200, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        #x = F.relu(x)\n",
    "        output = 1.5*torch.nn.functional.tanh(x)\n",
    "        return output.squeeze()\n",
    "    \n",
    "\n",
    "if func_run == \"abs\":\n",
    "    net_learner1 = CNN_X()\n",
    "else:\n",
    "    net_learner1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, k),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(k, 200),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(200, 2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(2, 1),\n",
    "            torch.nn.Tanh(),\n",
    "            )\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "net_learner2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, k),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(k, 200),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(200, 1),\n",
    "            )\n",
    "\n",
    "\n",
    "#learner = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_t, n_hidden), nn.LeakyReLU(),\n",
    "#                        nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "#                        nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "#adversary_fn = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_z, n_hidden), nn.LeakyReLU(),\n",
    "#                             nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "#                             nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "net_adversary = torch.nn.Sequential(nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(8, k),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),                        \n",
    "            torch.nn.Linear(k, 200), #200\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),                        \n",
    "            torch.nn.Linear(200, 1),\n",
    "            )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5026298d-d7a5-4dda-8cab-be86cd62005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner1 = net_learner1.double()\n",
    "\n",
    "learner2 = net_learner2.double()\n",
    "\n",
    "adversary = net_adversary.double() #fc_z_agmm(n_instruments, n_hidden, dropout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f57f02b5-36dd-49eb-b0cc-ba8128ab5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mliv.neuralnet import ADeepCI"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f481d19-7de8-4794-b01d-aac7f308be0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%capture\n",
    "res1 = ADeepCI(learner1, adversary).fit(X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, \n",
    "                  X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z, \n",
    "            learner_l2=1e-3, adversary_l2=1e-4, adversary_norm_reg=1e-3,\n",
    "            learner_lr=0.001, adversary_lr=0.001, n_epochs=n_epochs, bs=bs, train_learner_every=1, train_adversary_every=1,\n",
    "            ols_weight=0., warm_start=False, logger=None, model_dir='.', device=None, verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3da70def-eaca-438a-ba23-6159b3f65ae4",
   "metadata": {},
   "source": [
    "%%capture\n",
    "res2 = ADeepCI(learner2, adversary).fit(X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, \n",
    "                  X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z, \n",
    "            learner_l2=1e-3, adversary_l2=1e-4, adversary_norm_reg=1e-3,\n",
    "            learner_lr=0.001, adversary_lr=0.001, n_epochs=n_epochs, bs=bs, train_learner_every=1, train_adversary_every=1,\n",
    "            ols_weight=0., warm_start=False, logger=None, model_dir='.', device=None, verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b475807e-7c3f-4249-a86e-fc1592accd3f",
   "metadata": {},
   "source": [
    "model_final1 = torch.load(os.path.join(res1.model_dir,\"epoch{}\".format(res1.n_epochs - 1)))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(X_2_a_k.T.squeeze().cpu().data.numpy(), model_final1(X_2_a_k).cpu().data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d2052d7-c997-44a8-acbc-82d6cb95d90e",
   "metadata": {},
   "source": [
    "model_final2 = torch.load(os.path.join(res2.model_dir,\"epoch{}\".format(res2.n_epochs - 1)))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(X_2_a_k.T.squeeze().cpu().data.numpy(), model_final2(X_2_a_k).cpu().data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f07b9098-991b-40be-a13a-7b2dc83f9eba",
   "metadata": {},
   "source": [
    "plt.scatter(X_2_a_k.T.squeeze().cpu().data.numpy(), aa(X_2_a_k).cpu().data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "871c54ad-2b82-4d0d-9f34-d958c4346925",
   "metadata": {},
   "source": [
    "np.random.seed(19104+1)\n",
    "X_1_a_j_test, X_2_a_j_test, X_1_a_k_test, X_2_a_k_test, X_1_b_j_test, X_2_b_j_test, X_1_b_k_test, X_2_b_k_test, Z_test = Simdata(10000,2,aa,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260eefdd-b635-4269-a71a-8230b3b9b7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9c9e750-4b98-4af9-830d-88b88b738cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = 2*(X_1_a_j_test.T.squeeze().cpu().data.numpy() + model_final(X_2_a_j_test).squeeze().cpu().data.numpy() > \\\n",
    "#            X_1_a_k_test.T.squeeze().cpu().data.numpy() + model_final(X_2_a_k_test).squeeze().cpu().data.numpy())-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7448dad5-4979-4d1c-90ae-68dd097c5139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = 1*((y_pred+100)>0) # all ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "195ec110-5f6f-4121-9415-840af5e03a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2071fc32-0799-425c-9eec-bf036242de60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.9/dist-packages (0.13.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.9/dist-packages (from statsmodels) (0.5.3)\n",
      "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.9/dist-packages (from statsmodels) (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from statsmodels) (1.23.1)\n",
      "Requirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.9/dist-packages (from statsmodels) (1.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=21.3->statsmodels) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.25->statsmodels) (2022.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from patsy>=0.5.2->statsmodels) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98fffc74-f5fc-4dde-a45f-7bc7b44e0fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "MSEs = []\n",
    "Biases = []\n",
    "\n",
    "for kk in range (0,3):\n",
    "    np.random.seed(kk)\n",
    "    X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z = Simdata(10000,2,aa,rho)\n",
    "    \n",
    "    res1 = ADeepCI(learner1, adversary).fit(X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, \n",
    "                  X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z, \n",
    "            learner_l2=1e-3, adversary_l2=1e-4, adversary_norm_reg=1e-3,\n",
    "            learner_lr=0.001, adversary_lr=0.001, n_epochs=n_epochs, bs=bs, train_learner_every=1, train_adversary_every=1,\n",
    "            ols_weight=0., warm_start=False, logger=None, model_dir='.', device=None, verbose=1)\n",
    "    model_final = torch.load(os.path.join(res1.model_dir,\"epoch{}\".format(res1.n_epochs - 1)))\n",
    "\n",
    "    y = model_final(X_2_a_k).cpu().data.numpy()\n",
    "    if y.ndim == 2:\n",
    "        x = aa(X_2_a_k).cpu().data.numpy()[:, np.newaxis]\n",
    "    else:\n",
    "        x = aa(X_2_a_k).cpu().data.numpy()\n",
    "\n",
    "\n",
    "    MSE = np.mean((y - x) ** 2)\n",
    "    MSEs.append(MSE)\n",
    "    Bias = np.mean(y-x)\n",
    "    Biases.append(Bias)\n",
    "\n",
    "    \n",
    "print(np.mean(MSEs))\n",
    "print(np.mean(Biases))\n",
    "\n",
    "\n",
    "##Fit and summarize OLS model\n",
    "#x = sm.add_constant(x, prepend=False)\n",
    "#mod = sm.OLS(y,x)\n",
    "#res = mod.fit()\n",
    "#print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8cf1ef0-3ded-4ca2-b0b8-34cce5389f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32554811808562795\n",
      "0.016536883248568002\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(MSEs))\n",
    "print(np.mean(Biases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2331c3ea-477a-48e5-8043-cf92625c37cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(X_2_a_k.T.squeeze().cpu().data.numpy(), model_final(X_2_a_k).cpu().data.numpy())\n",
    "plt.savefig(func_run+str(J)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fcfa4cc-1305-4132-8ecb-fe5d9498a716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09278319546823507, 0.2036406232802473, -0.24681316900277833]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "babc2dbc-d907-437c-922f-82847fb37159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11060713018974976, 0.5530067408554494, 0.3130304832116847]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4aecd88c-d913-4ae2-b403-45eccf7d3051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape == x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca49db5-7af3-469e-914f-8551393fb8b5",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76beb017-db9b-4f3e-8fc3-1487df6628ce",
   "metadata": {},
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e84f693-406a-47d0-b3c8-63d5de1aff2c",
   "metadata": {},
   "source": [
    "X_1 = np.concatenate((X_1_a_j.cpu().data.numpy(),X_2_a_j.cpu().data.numpy()),axis = 1)\n",
    "X_2 = np.concatenate((X_1_a_k.cpu().data.numpy(),X_2_a_k.cpu().data.numpy()),axis = 1)\n",
    "y_1 = np.ones(X_1.shape[0])\n",
    "y_2 = np.zeros(X_1.shape[0])\n",
    "\n",
    "X = np.concatenate((X_1,X_2), axis = 0)\n",
    "y = np.concatenate((y_1,y_2), axis = 0)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb42a39d-4db4-495c-9e63-65ecb36ef7cb",
   "metadata": {},
   "source": [
    "X_a_j_test = np.concatenate((X_1_a_j_test.cpu().data.numpy(),X_2_a_j_test.cpu().data.numpy()),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "929fef06-3a85-4ad9-beea-219e9b2c4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_clf = 2*clf.predict(X_a_j_test)-1 #1 or -1\n",
    "#y_clf = 1*((y_pred_clf+100)>0) # all ones\n",
    "\n",
    "#f1_score(y_clf,y_pred_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43f1e22-8c45-422a-a9be-57e38f7337cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904dcf1f-b1be-4910-8832-6c2055338737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76214db8-5f65-43a2-9a9d-2d78739e9171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5fe456-6a6e-43c5-ac49-ee9baa0bd364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20d1d8ee-f8bf-462d-b3e0-42b5f31fdf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sin\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, precision_score, recall_score, roc_auc_score\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "method = func_run\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def compute_stats(d1_train, d2_train, y_train, d1_test, d2_test, y_test, N, mode):\n",
    "\n",
    "\n",
    "    print(\"J:\",J, \"rho:\",rho, \"method:\",method, \"mode:\",mode)\n",
    "\n",
    "\n",
    "    torch.manual_seed(2)    # reproducible\n",
    "\n",
    "    x1 = torch.tensor(d1_train, dtype=torch.float32)\n",
    "    x2 = torch.tensor(d2_train, dtype=torch.float32)\n",
    "    y  = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "    # torch can only train on Variable, so convert them to Variable\n",
    "    x1, x2, y = Variable(x1), Variable(x2), Variable(y)\n",
    "\n",
    "\n",
    "    if mode == 'PPHI':\n",
    "        net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, 1),\n",
    "            torch.nn.Flatten(0, 1)\n",
    "            )\n",
    "    elif mode == 'polyPPHI':\n",
    "        net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 1),\n",
    "            torch.nn.Flatten(0, 1)\n",
    "            )\n",
    "    else:\n",
    "        net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, 300),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(300, 200),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(200, 1),\n",
    "            )\n",
    "\n",
    "\n",
    "    # print(net)  # net architecture\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "    if mode == 'PPHI':\n",
    "        p = torch.tensor([1])\n",
    "        x10 = torch.unsqueeze(x1[:,0],dim=1)\n",
    "        x20 = torch.unsqueeze(x2[:,0],dim=1)\n",
    "        x11 = torch.unsqueeze(x1[:,1:],dim=1).pow(p)\n",
    "        x21 = torch.unsqueeze(x2[:,1:],dim=1).pow(p)\n",
    "    elif mode == 'polyPPHI':\n",
    "        p = torch.tensor([1,2])\n",
    "        x10 = torch.unsqueeze(x1[:,0],dim=1)\n",
    "        x20 = torch.unsqueeze(x2[:,0],dim=1)\n",
    "        x11 = torch.unsqueeze(x1[:,1:],dim=1).pow(p)\n",
    "        x21 = torch.unsqueeze(x2[:,1:],dim=1).pow(p)\n",
    "    else:\n",
    "        x10 = torch.unsqueeze(x1[:,0],dim=1)\n",
    "        x20 = torch.unsqueeze(x2[:,0],dim=1)\n",
    "        x11 = torch.unsqueeze(x1[:,1:],dim=1)\n",
    "        x21 = torch.unsqueeze(x2[:,1:],dim=1)\n",
    "\n",
    "\n",
    "    def deepci_loss(first, second, y):\n",
    "        diff1 = torch.reshape(first - second, (-1,))\n",
    "        diff = diff1*(y>0) + (-diff1)*(y<0)\n",
    "        loss = torch.mean(torch.minimum(torch.zeros(diff.size()),diff)**2)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCH = 100\n",
    "    torch_dataset = Data.TensorDataset(x10, x11, x20, x21, y)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True, num_workers=2,)\n",
    "    iteration = 0\n",
    "\n",
    "    # start training\n",
    "    for epoch in range(EPOCH):\n",
    "        for step, (batch_x10, batch_x11, batch_x20, batch_x21, batch_y) in enumerate(loader): # for each training step\n",
    "\n",
    "            b_x10 = Variable(batch_x10)\n",
    "            b_x11 = Variable(batch_x11)\n",
    "            b_x20 = Variable(batch_x20)\n",
    "            b_x21 = Variable(batch_x21)\n",
    "            b_y = Variable(batch_y)\n",
    "\n",
    "            prediction_1 = b_x10 + net(b_x11)     # input x and predict based on x\n",
    "            prediction_2 = b_x20 + net(b_x21)\n",
    "\n",
    "            loss = deepci_loss(prediction_1, prediction_2, b_y)     # must be (1. nn output, 2. target)\n",
    "            #if iteration%500 == 0:\n",
    "            #    print(loss)\n",
    "            iteration +=1    \n",
    "            optimizer.zero_grad()   # clear gradients for next train\n",
    "            loss.backward()         # backpropagation, compute gradients\n",
    "            optimizer.step()        # apply gradients\n",
    "\n",
    "\n",
    "    x1_test = torch.tensor(d1_test, dtype=torch.float32)\n",
    "    x2_test = torch.tensor(d2_test, dtype=torch.float32)\n",
    "    y       = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    if mode == 'PPHI':\n",
    "        x10_test = torch.unsqueeze(x1_test[:,0],dim=1)\n",
    "        x20_test = torch.unsqueeze(x2_test[:,0],dim=1)\n",
    "        x11_test = torch.unsqueeze(x1_test[:,1:],dim=1).pow(p)\n",
    "        x21_test = torch.unsqueeze(x2_test[:,1:],dim=1).pow(p)\n",
    "    elif mode == 'polyPPHI':\n",
    "        x10_test = torch.unsqueeze(x1_test[:,0],dim=1)\n",
    "        x20_test = torch.unsqueeze(x2_test[:,0],dim=1)\n",
    "        x11_test = torch.unsqueeze(x1_test[:,1:],dim=1).pow(p)\n",
    "        x21_test = torch.unsqueeze(x2_test[:,1:],dim=1).pow(p)\n",
    "    else:\n",
    "        x10_test = torch.unsqueeze(x1_test[:,0],dim=1)\n",
    "        x20_test = torch.unsqueeze(x2_test[:,0],dim=1)\n",
    "        x11_test = torch.unsqueeze(x1_test[:,1:],dim=1)\n",
    "        x21_test = torch.unsqueeze(x2_test[:,1:],dim=1)\n",
    "\n",
    "\n",
    "    if mode == 'NN':\n",
    "        y_pred = 2*(x10_test.flatten() + net(x11_test).data.numpy().flatten() > \\\n",
    "                x20_test.flatten() + net(x21_test).data.numpy().flatten())-1\n",
    "    else:\n",
    "        y_pred = 2*((x10_test + net(x11_test)).flatten() > \\\n",
    "                (x20_test + net(x21_test)).flatten())-1\n",
    "\n",
    "    f1 = f1_score(y.numpy(),y_pred.numpy())\n",
    "    \n",
    "    yy = net(x11_test).cpu().data.numpy()\n",
    "    xx = aa(x1_test[:,1:]).cpu().data.numpy()[:, np.newaxis]\n",
    "\n",
    "    #xx = sm.add_constant(xx, prepend=False)\n",
    "    ## Fit and summarize OLS model\n",
    "    #mod = sm.OLS(yy,xx)\n",
    "    #res = mod.fit()\n",
    "    #print(res.summary())\n",
    "    print(yy.shape)\n",
    "    print(xx.shape)\n",
    "    \n",
    "    MSE = np.mean((yy - xx) ** 2)\n",
    "    Bias = np.mean(yy-xx)\n",
    "        \n",
    "    return MSE, Bias\n",
    "\n",
    "\n",
    "def simulateData(N, J, K, func, rho, sim):\n",
    "    np.random.seed(sim)\n",
    "    D = np.random.uniform(-1,1,(N,J + 1,K))\n",
    "    x1 = np.array([])\n",
    "    x2 = np.array([])\n",
    "    y  = np.array([])\n",
    "    for n in range(N):\n",
    "        err = np.random.normal(0,0.5) # epsilon_m\n",
    "        D[n,1:,1] = 5*D[n,1:,1] + rho*err\n",
    "        D[n,1:,0] = D[n,1:,0] \n",
    "        choice = np.argmax(D[n,:,0] + 2*func(D[n,:,1:]) + np.random.normal(0,3,(1,J + 1)) + err) # x_0+f(x_1) for each product\n",
    "        if choice == 0:\n",
    "            continue\n",
    "        for j in range(1, J+1):\n",
    "            if j == choice:\n",
    "                continue\n",
    "            else:\n",
    "                #print(D[n,choice,:])\n",
    "                if x1.size == 0:\n",
    "                    x1 = D[n,choice,:]\n",
    "                    x2 = D[n,j,:]\n",
    "                    y  = np.array([1])\n",
    "                else:    \n",
    "                    x1 = np.c_[x1, D[n,choice,:]]\n",
    "                    x2 = np.c_[x2, D[n,j,:]]\n",
    "                    y  = np.c_[y,np.array([1])]\n",
    "    return x1.T, x2.T, y.T\n",
    "\n",
    "\n",
    "print(method)\n",
    "\n",
    "\n",
    "def runConfig(J, rho, method, mode):\n",
    "    N = 2000\n",
    "    K = 2\n",
    "    a, b = get_function(method)\n",
    "    MSEs = []\n",
    "    for i in range(1,2): \n",
    "        d1_train, d2_train, y_train = simulateData(N, J, K, a, rho, i)\n",
    "        d1_test,  d2_test,  y_test  = simulateData(N, J, K, a, rho, i+1)\n",
    "        MSE, Bias = compute_stats(d1_train, d2_train, y_train, d1_test, d2_test, y_test, d1_train.shape[0], mode)\n",
    "        MSEs.append(MSE)\n",
    "        Biases.append(Bias)\n",
    "\n",
    "    return np.mean(MSEs), np.mean(Biases)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8e46101-ac6b-423f-bf40-20b9d81f6f6e",
   "metadata": {},
   "source": [
    "def get_function(func_str):\n",
    "    if func_str == \"abs\":\n",
    "        return (lambda x: (-1+0.4*np.abs(x@np.ones((1,1)))).flatten(), \n",
    "                lambda x: (-1+0.4*torch.abs(x@np.ones((1,1)))).flatten())\n",
    "    elif func_str == \"log\":\n",
    "        return (lambda x: 2*np.log(np.abs(x@np.ones((1,1)))).flatten(), \n",
    "                lambda x: 2*torch.log(torch.abs(x@np.ones((1,1)))).flatten())\n",
    "    elif func_str == \"sin\":\n",
    "        return (lambda x: np.sin(x@np.ones((1,1))).flatten(), \n",
    "                lambda x: torch.sin(x@np.ones((1,1))).flatten())\n",
    "    else:\n",
    "        return (lambda x: np.sign(np.abs(np.abs(x@np.ones((1,1)))-5)-2).flatten(), \n",
    "                lambda x: torch.sign(torch.abs(torch.abs(x@np.ones((1,1)))-5)-2).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1260198d-bb5e-4dc2-b88f-b0624bafedc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 5 rho: 0.2 method: sin mode: polyPPHI\n",
      "(6748, 1)\n",
      "(6748, 1)\n",
      "0.42300344\n",
      "-0.02205371727520196\n"
     ]
    }
   ],
   "source": [
    "mode = 'polyPPHI'\n",
    "\n",
    "result1, result2 = runConfig(J, rho, method, mode)\n",
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e3b7767-5393-410d-a32b-b97eb96eb355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 5 rho: 0.2 method: sin mode: PPHI\n",
      "(6748, 1)\n",
      "(6748, 1)\n",
      "0.74351573\n",
      "-0.13517842189450238\n"
     ]
    }
   ],
   "source": [
    "mode = 'PPHI'\n",
    "\n",
    "result1, result2 = runConfig(J, rho, method, mode)\n",
    "print(result1)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc54d53-a401-485b-a8ba-b177f975c4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bddb6c94227d8177e61600db041b4cc1c87a884063126e29a3bfd540ed5196fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
