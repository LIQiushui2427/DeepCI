{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d77d2b9-1d2b-4d84-8c0e-2b51d3a546e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:\\DeepCI\\local_notebooks\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 182] 操作系统无法运行 %1。 Error loading \"d:\\ProgramFiles\\anaconda3\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mf:\\DeepCI\\local_notebooks\\final_ADeepCI_MINIST_Experiments_fromsinglevar.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/DeepCI/local_notebooks/final_ADeepCI_MINIST_Experiments_fromsinglevar.ipynb#X56sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mitertools\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/DeepCI/local_notebooks/final_ADeepCI_MINIST_Experiments_fromsinglevar.ipynb#X56sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m \n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/DeepCI/local_notebooks/final_ADeepCI_MINIST_Experiments_fromsinglevar.ipynb#X56sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/DeepCI/local_notebooks/final_ADeepCI_MINIST_Experiments_fromsinglevar.ipynb#X56sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/DeepCI/local_notebooks/final_ADeepCI_MINIST_Experiments_fromsinglevar.ipynb#X56sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramFiles\\anaconda3\\lib\\site-packages\\torch\\__init__.py:129\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m     err \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mWinError(last_error)\n\u001b[0;32m    128\u001b[0m     err\u001b[39m.\u001b[39mstrerror \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m Error loading \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdll\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m or one of its dependencies.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 129\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[0;32m    130\u001b[0m \u001b[39melif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     is_loaded \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 182] 操作系统无法运行 %1。 Error loading \"d:\\ProgramFiles\\anaconda3\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "seedNum = 888\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "tf.random.set_seed(seedNum)\n",
    "np.random.seed(seedNum)\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import sys, os\n",
    "print(os.getcwd())\n",
    "# os.chdir('/home/lqs/Desktop/vscproj/DeepCI')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### import from our files\n",
    "from mliv.dgps import get_data, get_tau_fn, fn_dict\n",
    "from mliv.neuralnet.utilities import log_metrics, plot_results, hyperparam_grid,\\\n",
    "                                     hyperparam_mult_grid, eval_performance\n",
    "from mliv.neuralnet.mnist_dgps import AbstractMNISTxz\n",
    "from mliv.neuralnet import AGMM,KernelLayerMMDGMM\n",
    "from mliv.neuralnet.rbflayer import gaussian, inverse_multiquadric\n",
    "from mliv.neuralnet import ADeepCI\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# ! pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aaf8b10a-8dd2-42d5-9c51-7a12f027e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train/255\n",
    "X_test  = X_test/255\n",
    "(example_X_train,example_y_train) = (X_train[:2000], y_train[:2000])\n",
    "(example_X_test,example_y_test) = (X_test[:2000], y_test[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fab882a9-0c11-4b14-8b59-c6e96ab30e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_train\n",
    "b = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "200e8919-53b0-42e5-bdac-f85441a5b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_run = \"none\"\n",
    "n_epochs = 60\n",
    "bs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8552fff8-2417-4e18-bcdb-f725e23ca923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d331d3a7-f7c5-4fae-8334-4120b9635831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function(func_str):\n",
    "    if func_str == \"abs\":\n",
    "        return (lambda x: (-1+0.4*np.abs(x)).flatten(), \n",
    "                lambda x: (-1+0.4*torch.abs(x)).flatten())\n",
    "    elif func_str == \"log\":\n",
    "        return (lambda x: 2*np.log(np.abs(x)).flatten(), \n",
    "                lambda x: 2*torch.log(torch.abs(x)).flatten())\n",
    "    elif func_str == \"sin\":\n",
    "        return (lambda x: (0.5+0.5*np.sin(x)).flatten(), \n",
    "                lambda x: (0.5+0.5*torch.sin(x)).flatten())\n",
    "    elif func_str == \"none\":\n",
    "        return (lambda x: 0.2*x.flatten(), \n",
    "                lambda x: 0.2*torch.Tensor(x).flatten())\n",
    "    else:\n",
    "        return (lambda x: np.sign(np.abs(np.abs(x)-5)-2).flatten(), \n",
    "                lambda x: torch.sign(torch.abs(torch.abs(x)-5)-2).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afb4ee77-a552-4026-9dac-14abf4b70b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simdata(NUM_I,seed,func,rho): #a = y_train/test, b = X_train/test\n",
    "    \n",
    "    np.random.seed(seed)    \n",
    "    X_1_a_j = [] \n",
    "    X_2_a_j = [] \n",
    "    X_1_a_k = [] \n",
    "    X_2_a_k = [] \n",
    "    X_1_b_j = [] \n",
    "    X_2_b_j = [] \n",
    "    X_1_b_k = [] \n",
    "    X_2_b_k = []\n",
    "    Z       = []\n",
    "    \n",
    "\n",
    "    X_2_a_j_t = [] \n",
    "    X_2_a_k_t = [] \n",
    "    X_2_b_j_t = [] \n",
    "    X_2_b_k_t = []\n",
    "\n",
    "    for i in tqdm(range(0,NUM_I)):\n",
    "        J = np.random.randint(4,10) # number of choice\n",
    "              \n",
    "        \n",
    "        samplea = np.array(random.sample(list(np.arange(a.shape[0])),J)) # a list of index\n",
    "        samplea = np.expand_dims(samplea, axis=1)\n",
    "        ej = np.concatenate([a[i] for i in samplea],axis = None) # a list of number on images\n",
    "        ej = [i for i in ej.tolist()]\n",
    "        ej = np.float_(ej)\n",
    "\n",
    "        X_1_a = np.random.uniform(-1,1,J) #customer a\n",
    "        X_2_a = ej\n",
    "        X_2_a_pic = [torch.Tensor(b[i]) for i in samplea]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        sampleb = np.array(random.sample(list(np.arange(a.shape[0])),J)) # a list of index\n",
    "        sampleb = np.expand_dims(sampleb, axis=1)\n",
    "        ej = np.concatenate([a[i] for i in sampleb],axis = None) # a list of number on images\n",
    "        ej = [i for i in ej.tolist()]\n",
    "        ej = np.float_(ej)\n",
    "        \n",
    "        X_1_b = np.random.uniform(-1,1,J) #customer b\n",
    "        X_2_b = ej\n",
    "        X_2_b_pic = [torch.Tensor(b[i]) for i in sampleb]\n",
    "        \n",
    "        \n",
    "        \n",
    "        xi  = np.random.normal(0,0.5,J)    # same across all customers\n",
    "        \n",
    "        X_2_a = X_2_a #+ rho*xi  #customer a endogeneity remove for now\n",
    "        X_2_b = X_2_b #+ rho*xi  #customer b endogeneity remove for now\n",
    "        \n",
    "        u_a   = X_1_a + 2*func(X_2_a) + xi + np.random.normal(0,3,J) # \\epsilon_{a} # 3 for score\n",
    "        u_b   = X_1_b + 2*func(X_2_b) + xi + np.random.normal(0,3,J) # \\epsilon_{b}\n",
    "        \n",
    "        choice_j = np.argmax(u_a) # return the index of product in the sample that customer a chose, we assume customer a as choose j\n",
    "        choice_k = np.argmax(u_b) # return the index of product in the sample that customer b chose, we assume customer b as choose k\n",
    "               \n",
    "        if choice_j == choice_k:\n",
    "            continue\n",
    "        else:  \n",
    "\n",
    "            X_1_a_j.append(X_1_a[choice_j])\n",
    "            X_2_a_j.append(X_2_a_pic[choice_j])\n",
    "            X_1_a_k.append(X_1_a[choice_k])\n",
    "            X_2_a_k.append(X_2_a_pic[choice_k])\n",
    "            \n",
    "            X_1_b_j.append(X_1_b[choice_j]) \n",
    "            X_2_b_j.append(X_2_b_pic[choice_j]) \n",
    "            X_1_b_k.append(X_1_b[choice_k]) \n",
    "            X_2_b_k.append(X_2_b_pic[choice_k])\n",
    "            \n",
    "            \n",
    "            \n",
    "            X_2_a_j_t.append(X_2_a[choice_j])\n",
    "            X_2_a_k_t.append(X_2_a[choice_k])             \n",
    "            X_2_b_j_t.append(X_2_b[choice_j]) \n",
    "            X_2_b_k_t.append(X_2_b[choice_k])\n",
    "            #Z.append(np.array([X_1_a[choice_j], X_2_a[choice_j], X_1_a[choice_k], X_2_a[choice_k],X_1_b[choice_j], X_2_b[choice_j], X_1_b[choice_k], X_2_b[choice_k]]))\n",
    "            Z.append(np.array([X_1_a[choice_j],X_1_a[choice_k],X_1_b[choice_j],X_1_b[choice_k]]))\n",
    "            \n",
    "    X_2_a_j = torch.cat(X_2_a_j, out=torch.Tensor(len(X_2_a_j), 28, 28))\n",
    "    X_2_a_k = torch.cat(X_2_a_k, out=torch.Tensor(len(X_2_a_k), 28, 28))\n",
    "    X_2_b_j = torch.cat(X_2_b_j, out=torch.Tensor(len(X_2_b_j), 28, 28))\n",
    "    X_2_b_k = torch.cat(X_2_b_k, out=torch.Tensor(len(X_2_b_k), 28, 28))\n",
    "\n",
    "    #X_1_a_j = torch.Tensor(X_1_a_j)\n",
    "    #X_1_a_k = torch.Tensor(X_1_a_k)\n",
    "    #X_1_b_j = torch.Tensor(X_1_b_j)\n",
    "    #X_1_b_k = torch.Tensor(X_1_b_k)\n",
    "            \n",
    "\n",
    "    \n",
    "    return torch.Tensor(X_1_a_j).reshape((-1,1)).double(), X_2_a_j.unsqueeze(1), \\\n",
    "torch.Tensor(X_1_a_k).reshape((-1,1)).double(), X_2_a_k.unsqueeze(1), torch.Tensor(X_1_b_j).reshape((-1,1)).double(), \\\n",
    "X_2_b_j.unsqueeze(1), torch.Tensor(X_1_b_k).reshape((-1,1)).double(), X_2_b_k.unsqueeze(1), \\\n",
    "torch.tensor(Z, dtype=torch.float64),\\\n",
    "torch.Tensor(X_2_a_j_t).reshape((-1,1)).unsqueeze(1).double(), torch.Tensor(X_2_a_k_t).reshape((-1,1)).unsqueeze(1).double(),\\\n",
    "torch.Tensor(X_2_b_j_t).reshape((-1,1)).unsqueeze(1).double(), torch.Tensor(X_2_b_k_t).reshape((-1,1)).unsqueeze(1).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16ad8027-3000-4929-b8d3-47a42661db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa,bb = get_function(func_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a38b07e4-f0c0-4b72-96d6-925250d5953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:16<00:00, 310.30it/s]\n"
     ]
    }
   ],
   "source": [
    "X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z,  X_2_a_j_t, X_2_a_k_t,  X_2_b_j_t,  X_2_b_k_t= Simdata(5000,2,aa,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af377986-f660-44fb-bebf-196143c5df74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4140, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image = X_2_a_k[6]\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(image.squeeze(0), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(X_2_a_k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93656844-b6ad-4614-ae56-82e55e9432f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95b4d8d7-1c6f-4b3f-bb7d-cfcc9124013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/lqs/Desktop/vscproj/DeepCI/local_notebooks', '/home/lqs/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles', '/home/lqs/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/lib/python', '/home/lqs/anaconda3/lib/python39.zip', '/home/lqs/anaconda3/lib/python3.9', '/home/lqs/anaconda3/lib/python3.9/lib-dynload', '', '/home/lqs/anaconda3/lib/python3.9/site-packages', '/home/lqs/anaconda3/lib/python3.9/site-packages/IPython/extensions', '/home/lqs/.ipython', '/notebooks/AdversarialGMM/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path\n",
    "print(sys.path)\n",
    "sys.path.append('/notebooks/AdversarialGMM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "884b4136-77ea-4c22-8e12-857fe1d8954a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1768071-a988-45df-a18e-13de550552a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a82e63c-963d-4dec-9ace-4f6d403f0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Z_agmm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Z_agmm, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "class CNN_Z_kernel(nn.Module):\n",
    "    def __init__(self, g_features=100):\n",
    "        super(CNN_Z_kernel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, g_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "class CNN_X(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_X, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.finallayer = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 1, 28, 28)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.finallayer(x)\n",
    "        output = x #F.tanh(x) #F.softmax(x, dim=1) #x\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e893ec27-77fd-4945-a9ee-f4ae0fb6a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_z_kernel(n_z, n_hidden, g_features, dropout_p):\n",
    "    FC_Z_kernel = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, g_features),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    return FC_Z_kernel\n",
    "\n",
    "\n",
    "def fc_z_agmm(n_z, n_hidden, dropout_p):\n",
    "    FC_Z_agmm = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_Z_agmm\n",
    "\n",
    "\n",
    "def fc_x(n_t, n_hidden, dropout_p):\n",
    "    FC_X = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_t, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5aab8430-e3fa-4560-a3da-8e0178dbdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 500\n",
    "n_hidden = 300\n",
    "n_instruments = 1\n",
    "dropout_p = 0.1\n",
    "\n",
    "net_learner = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, k),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(k, 200),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(200, 1),\n",
    "            )\n",
    "\n",
    "#learner = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_t, n_hidden), nn.LeakyReLU(),\n",
    "#                        nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "#                        nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "#adversary_fn = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_z, n_hidden), nn.LeakyReLU(),\n",
    "#                             nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "#                             nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "net_adversary = torch.nn.Sequential(nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(4, k),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),                        \n",
    "            torch.nn.Linear(k, 200), #200\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),                        \n",
    "            torch.nn.Linear(200, 1),\n",
    "            )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f3a26a7-179c-4b94-a666-2c6a40f03131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lqs/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "resnet50 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "resnet50.fc = nn.Identity()\n",
    "class Net(nn.Module):\n",
    "    #This defines the structure of the NN.\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.resnet = resnet50\n",
    "        self.fc1 = nn.Linear(2048, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Convolutional Layer/Pooling Layer/Activation\n",
    "        x = self.resnet(x) \n",
    "        #Convolutional Layer/Dropout/Pooling Layer/Activation\n",
    "        #Fully Connected Layer/Activation\n",
    "        x = self.fc1(x)\n",
    "        return x.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7ec5d7a-a5cd-4ef3-a72e-0387065fa0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={}\n",
    "kwargs={}\n",
    "args['batch_size']=100\n",
    "args['test_batch_size']=1000\n",
    "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
    "args['lr']=0.0005 #Learning rate is how fast it will decend. \n",
    "args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
    "\n",
    "args['seed']=1 #random seed\n",
    "args['log_interval']=10\n",
    "args['cuda']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af8e7340-744a-419f-ba28-ed4aa0ada630",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       \n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=True, **kwargs)\n",
    "\n",
    "import torchvision.transforms as T\n",
    "transform = T.Resize((32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfb36100-e368-4ba3-b0f2-1df71249c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        #Variables in Pytorch are differenciable. \n",
    "        #data = transform(data)\n",
    "        #data = torch.concat([data,data,data],axis=1)\n",
    "        #\n",
    "        data = data.float()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #This will zero out the gradients for this batch. \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
    "        loss = F.mse_loss(output.float(), target.float())\n",
    "        #dloss/dx for every Variable \n",
    "        loss.backward()\n",
    "        #to do a one-step update on our parameter.\n",
    "        optimizer.step()\n",
    "        #Print out the loss periodically. \n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        data = transform(data)\n",
    "        data = torch.concat([data,data,data],axis=1)\n",
    "        data = data.float()\n",
    "        output = model(data)\n",
    "        test_loss += F.mse_loss(output, target/10)\n",
    "        \n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(\n",
    "        test_loss, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "988ed727-a48d-4d1e-babb-0a3bf9ce94a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_X(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_X, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        # output = F.log_softmax(x, dim=1)\n",
    "        return x.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "656538b7-b70d-4f25-a3d6-639be94476de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net_X(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net_X()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9eabc04-ea63-4e93-a804-8fe3bd4833bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_856466/4150518467.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero."
     ]
    }
   ],
   "source": [
    "model = Net_X()\n",
    "if args['cuda']:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(1, 20):\n",
    "    train(epoch)\n",
    "    #test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7870d0d-2397-4fbf-811b-ffc4d4b07475",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.Tensor(X_train[:100]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084a0b0-c468-4c43-a924-efc6bc1b820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(d.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e487c-7675-47d1-bdda-56f999c4dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((model(d.cuda()).cpu().detach().numpy() - y_train[:100])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026298d-d7a5-4dda-8cab-be86cd62005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = model.to('cpu')\n",
    "\n",
    "adversary = net_adversary.double() #fc_z_agmm(n_instruments, n_hidden, dropout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f02b5-36dd-49eb-b0cc-ba8128ab5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mliv.neuralnet import ADeepCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c472a-034d-487b-b8c7-1ae64e709cb1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = ADeepCI(learner, adversary).fit(X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, \n",
    "                  X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z, \n",
    "            learner_l2=1e-3, adversary_l2=1e-4, adversary_norm_reg=1e-3,\n",
    "            learner_lr=0.001, adversary_lr=0.001, n_epochs=3, bs=bs, train_learner_every=4, train_adversary_every=1,\n",
    "            ols_weight=0., warm_start=True, logger=None, model_dir='.', device= 0, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b71fae-342e-42b8-b6bd-62c19a58007e",
   "metadata": {},
   "outputs": [],
   "source": [
    " model_final = model #torch.load(os.path.join(res.model_dir,\"epoch{}\".format(res.n_epochs - 1)))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(X_2_a_k_t.T.squeeze().cpu().data.numpy(), model_final(X_2_a_k.cuda()).cpu().data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e0df7-e0bc-4bad-95dc-0a80d9bdf053",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean((X_2_a_k_t.T.squeeze().cpu().data.numpy() - model_final(X_2_a_k.cuda()).cpu().data.numpy())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ec110-5f6f-4121-9415-840af5e03a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_2_a_k_t.T.squeeze().cpu().data.numpy(), aa(X_2_a_k_t).cpu().data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635456c-a698-4ab0-8785-3dabc2c6fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ba91b-99bd-4608-a527-12000628b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = model_final(X_2_a_k).cpu().data.numpy()\n",
    "x = aa(X_2_a_k_t).cpu().data.numpy()\n",
    "\n",
    "print(np.mean((y - x) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c6707-ef9d-49a1-a653-90c9cfd0fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.add_constant(x, prepend=False)\n",
    "\n",
    "# Fit and summarize OLS model\n",
    "mod = sm.OLS(y,x)\n",
    "\n",
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2e668-851a-4f74-bee0-fcfbf7e8c1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62562ebf-725f-45b3-96b7-4d85be76c420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "bddb6c94227d8177e61600db041b4cc1c87a884063126e29a3bfd540ed5196fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
