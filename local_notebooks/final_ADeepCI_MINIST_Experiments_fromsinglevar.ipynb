{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d77d2b9-1d2b-4d84-8c0e-2b51d3a546e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seedNum = 888\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "tf.random.set_seed(seedNum)\n",
    "np.random.seed(seedNum)\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import sys, os\n",
    "print(os.getcwd())\n",
    "os.chdir('/media/lqs/李秋水的移动硬盘1/DeepCI')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### import from our files\n",
    "from mliv.dgps import get_data, get_tau_fn, fn_dict\n",
    "from mliv.neuralnet.utilities import log_metrics, plot_results, hyperparam_grid,\\\n",
    "                                     hyperparam_mult_grid, eval_performance\n",
    "from mliv.neuralnet.mnist_dgps import AbstractMNISTxz\n",
    "from mliv.neuralnet import AGMM,KernelLayerMMDGMM\n",
    "from mliv.neuralnet.rbflayer import gaussian, inverse_multiquadric\n",
    "from mliv.neuralnet import ADeepCI\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# ! pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8b10a-8dd2-42d5-9c51-7a12f027e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train/255\n",
    "X_test  = X_test/255\n",
    "(example_X_train,example_y_train) = (X_train[:2000], y_train[:2000])\n",
    "(example_X_test,example_y_test) = (X_test[:2000], y_test[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab882a9-0c11-4b14-8b59-c6e96ab30e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_train\n",
    "b = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e8919-53b0-42e5-bdac-f85441a5b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_run = \"none\"\n",
    "n_epochs = 200\n",
    "bs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8552fff8-2417-4e18-bcdb-f725e23ca923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331d3a7-f7c5-4fae-8334-4120b9635831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function(func_str):\n",
    "    if func_str == \"abs\":\n",
    "        return (lambda x: (-1+0.4*np.abs(x)).flatten(), \n",
    "                lambda x: (-1+0.4*torch.abs(x)).flatten())\n",
    "    elif func_str == \"log\":\n",
    "        return (lambda x: 2*np.log(np.abs(x)).flatten(), \n",
    "                lambda x: 2*torch.log(torch.abs(x)).flatten())\n",
    "    elif func_str == \"sin\":\n",
    "        return (lambda x: (0.5+0.5*np.sin(x)).flatten(), \n",
    "                lambda x: (0.5+0.5*torch.sin(x)).flatten())\n",
    "    elif func_str == \"none\":\n",
    "        return (lambda x: 0.2*x.flatten(), \n",
    "                lambda x: 0.2*torch.Tensor(x).flatten())\n",
    "    else:\n",
    "        return (lambda x: np.sign(np.abs(np.abs(x)-5)-2).flatten(), \n",
    "                lambda x: torch.sign(torch.abs(torch.abs(x)-5)-2).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4ee77-a552-4026-9dac-14abf4b70b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simdata(NUM_I,seed,func,rho): #a = y_train/test, b = X_train/test\n",
    "    \n",
    "    np.random.seed(seed)    \n",
    "    X_1_a_j = [] \n",
    "    X_2_a_j = [] \n",
    "    X_1_a_k = [] \n",
    "    X_2_a_k = [] \n",
    "    X_1_b_j = [] \n",
    "    X_2_b_j = [] \n",
    "    X_1_b_k = [] \n",
    "    X_2_b_k = []\n",
    "    Z       = []\n",
    "    \n",
    "\n",
    "    X_2_a_j_t = [] \n",
    "    X_2_a_k_t = [] \n",
    "    X_2_b_j_t = [] \n",
    "    X_2_b_k_t = []\n",
    "\n",
    "    for i in tqdm(range(0,NUM_I)):\n",
    "        J = np.random.randint(4,10) # number of choice\n",
    "              \n",
    "        \n",
    "        samplea = np.array(random.sample(list(np.arange(a.shape[0])),J)) # a list of index\n",
    "        samplea = np.expand_dims(samplea, axis=1)\n",
    "        ej = np.concatenate([a[i] for i in samplea],axis = None) # a list of number on images\n",
    "        ej = [i for i in ej.tolist()]\n",
    "        ej = np.float_(ej)\n",
    "\n",
    "        X_1_a = np.random.uniform(-1,1,J) #customer a\n",
    "        X_2_a = ej\n",
    "        X_2_a_pic = [torch.Tensor(b[i]) for i in samplea]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        sampleb = np.array(random.sample(list(np.arange(a.shape[0])),J)) # a list of index\n",
    "        sampleb = np.expand_dims(sampleb, axis=1)\n",
    "        ej = np.concatenate([a[i] for i in sampleb],axis = None) # a list of number on images\n",
    "        ej = [i for i in ej.tolist()]\n",
    "        ej = np.float_(ej)\n",
    "        \n",
    "        X_1_b = np.random.uniform(-1,1,J) #customer b\n",
    "        X_2_b = ej\n",
    "        X_2_b_pic = [torch.Tensor(b[i]) for i in sampleb]\n",
    "        \n",
    "        \n",
    "        \n",
    "        xi  = np.random.normal(0,0.5,J)    # same across all customers\n",
    "        \n",
    "        X_2_a = X_2_a #+ rho*xi  #customer a endogeneity remove for now\n",
    "        X_2_b = X_2_b #+ rho*xi  #customer b endogeneity remove for now\n",
    "        \n",
    "        u_a   = X_1_a + 2*func(X_2_a) + xi + np.random.normal(0,3,J) # \\epsilon_{a} # 3 for score\n",
    "        u_b   = X_1_b + 2*func(X_2_b) + xi + np.random.normal(0,3,J) # \\epsilon_{b}\n",
    "        \n",
    "        choice_j = np.argmax(u_a) # return the index of product in the sample that customer a chose, we assume customer a as choose j\n",
    "        choice_k = np.argmax(u_b) # return the index of product in the sample that customer b chose, we assume customer b as choose k\n",
    "               \n",
    "        if choice_j == choice_k:\n",
    "            continue\n",
    "        else:  \n",
    "\n",
    "            X_1_a_j.append(X_1_a[choice_j])\n",
    "            X_2_a_j.append(X_2_a_pic[choice_j])\n",
    "            X_1_a_k.append(X_1_a[choice_k])\n",
    "            X_2_a_k.append(X_2_a_pic[choice_k])\n",
    "            \n",
    "            X_1_b_j.append(X_1_b[choice_j]) \n",
    "            X_2_b_j.append(X_2_b_pic[choice_j]) \n",
    "            X_1_b_k.append(X_1_b[choice_k]) \n",
    "            X_2_b_k.append(X_2_b_pic[choice_k])\n",
    "            \n",
    "            \n",
    "            \n",
    "            X_2_a_j_t.append(X_2_a[choice_j])\n",
    "            X_2_a_k_t.append(X_2_a[choice_k])             \n",
    "            X_2_b_j_t.append(X_2_b[choice_j]) \n",
    "            X_2_b_k_t.append(X_2_b[choice_k])\n",
    "            #Z.append(np.array([X_1_a[choice_j], X_2_a[choice_j], X_1_a[choice_k], X_2_a[choice_k],X_1_b[choice_j], X_2_b[choice_j], X_1_b[choice_k], X_2_b[choice_k]]))\n",
    "            Z.append(np.array([X_1_a[choice_j],X_1_a[choice_k],X_1_b[choice_j],X_1_b[choice_k]]))\n",
    "            \n",
    "    X_2_a_j = torch.cat(X_2_a_j, out=torch.Tensor(len(X_2_a_j), 28, 28))\n",
    "    X_2_a_k = torch.cat(X_2_a_k, out=torch.Tensor(len(X_2_a_k), 28, 28))\n",
    "    X_2_b_j = torch.cat(X_2_b_j, out=torch.Tensor(len(X_2_b_j), 28, 28))\n",
    "    X_2_b_k = torch.cat(X_2_b_k, out=torch.Tensor(len(X_2_b_k), 28, 28))\n",
    "\n",
    "    #X_1_a_j = torch.Tensor(X_1_a_j)\n",
    "    #X_1_a_k = torch.Tensor(X_1_a_k)\n",
    "    #X_1_b_j = torch.Tensor(X_1_b_j)\n",
    "    #X_1_b_k = torch.Tensor(X_1_b_k)\n",
    "            \n",
    "\n",
    "    \n",
    "    return torch.Tensor(X_1_a_j).reshape((-1,1)).double(), X_2_a_j.unsqueeze(1), \\\n",
    "torch.Tensor(X_1_a_k).reshape((-1,1)).double(), X_2_a_k.unsqueeze(1), torch.Tensor(X_1_b_j).reshape((-1,1)).double(), \\\n",
    "X_2_b_j.unsqueeze(1), torch.Tensor(X_1_b_k).reshape((-1,1)).double(), X_2_b_k.unsqueeze(1), \\\n",
    "torch.tensor(Z, dtype=torch.float64),\\\n",
    "torch.Tensor(X_2_a_j_t).reshape((-1,1)).unsqueeze(1).double(), torch.Tensor(X_2_a_k_t).reshape((-1,1)).unsqueeze(1).double(),\\\n",
    "torch.Tensor(X_2_b_j_t).reshape((-1,1)).unsqueeze(1).double(), torch.Tensor(X_2_b_k_t).reshape((-1,1)).unsqueeze(1).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad8027-3000-4929-b8d3-47a42661db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa,bb = get_function(func_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b07e4-f0c0-4b72-96d6-925250d5953a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z,  X_2_a_j_t, X_2_a_k_t,  X_2_b_j_t,  X_2_b_k_t= Simdata(5000,2,aa,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af377986-f660-44fb-bebf-196143c5df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = X_2_a_k[6]\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(image.squeeze(0), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(X_2_a_k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93656844-b6ad-4614-ae56-82e55e9432f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b4d8d7-1c6f-4b3f-bb7d-cfcc9124013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path\n",
    "print(sys.path)\n",
    "sys.path.append('/notebooks/AdversarialGMM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b4136-77ea-4c22-8e12-857fe1d8954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1768071-a988-45df-a18e-13de550552a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82e63c-963d-4dec-9ace-4f6d403f0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Z_agmm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Z_agmm, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "class CNN_Z_kernel(nn.Module):\n",
    "    def __init__(self, g_features=100):\n",
    "        super(CNN_Z_kernel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, g_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "class CNN_X(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_X, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.finallayer = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 1, 28, 28)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.finallayer(x)\n",
    "        output = x #F.tanh(x) #F.softmax(x, dim=1) #x\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893ec27-77fd-4945-a9ee-f4ae0fb6a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_z_kernel(n_z, n_hidden, g_features, dropout_p):\n",
    "    FC_Z_kernel = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, g_features),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    return FC_Z_kernel\n",
    "\n",
    "\n",
    "def fc_z_agmm(n_z, n_hidden, dropout_p):\n",
    "    FC_Z_agmm = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_Z_agmm\n",
    "\n",
    "\n",
    "def fc_x(n_t, n_hidden, dropout_p):\n",
    "    FC_X = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_t, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab8430-e3fa-4560-a3da-8e0178dbdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 500\n",
    "n_hidden = 300\n",
    "n_instruments = 1\n",
    "dropout_p = 0.1\n",
    "\n",
    "net_learner = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, k),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(k, 200),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(200, 1),\n",
    "            )\n",
    "\n",
    "#learner = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_t, n_hidden), nn.LeakyReLU(),\n",
    "#                        nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "#                        nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "#adversary_fn = nn.Sequential(nn.Dropout(p=p), nn.Linear(n_z, n_hidden), nn.LeakyReLU(),\n",
    "#                             nn.Dropout(p=p), nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "#                             nn.Dropout(p=p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "net_adversary = torch.nn.Sequential(nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(4, k),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),                        \n",
    "            torch.nn.Linear(k, 200), #200\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),                        \n",
    "            torch.nn.Linear(200, 1),\n",
    "            )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a26a7-179c-4b94-a666-2c6a40f03131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "resnet50 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "resnet50.fc = nn.Identity()\n",
    "class Net(nn.Module):\n",
    "    #This defines the structure of the NN.\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.resnet = resnet50\n",
    "        self.fc1 = nn.Linear(2048, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Convolutional Layer/Pooling Layer/Activation\n",
    "        x = self.resnet(x) \n",
    "        #Convolutional Layer/Dropout/Pooling Layer/Activation\n",
    "        #Fully Connected Layer/Activation\n",
    "        x = self.fc1(x)\n",
    "        return x.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec5d7a-a5cd-4ef3-a72e-0387065fa0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={}\n",
    "kwargs={}\n",
    "args['batch_size']=100\n",
    "args['test_batch_size']=1000\n",
    "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
    "args['lr']=0.0005 #Learning rate is how fast it will decend. \n",
    "args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
    "\n",
    "args['seed']=1 #random seed\n",
    "args['log_interval']=200\n",
    "args['cuda']=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8e7340-744a-419f-ba28-ed4aa0ada630",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       \n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=True, **kwargs)\n",
    "\n",
    "import torchvision.transforms as T\n",
    "transform = T.Resize((32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb36100-e368-4ba3-b0f2-1df71249c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        #Variables in Pytorch are differenciable. \n",
    "        #data = transform(data)\n",
    "        #data = torch.concat([data,data,data],axis=1)\n",
    "        #\n",
    "        data = data.float()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #This will zero out the gradients for this batch. \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
    "        loss = F.mse_loss(output.float(), target.float())\n",
    "        #dloss/dx for every Variable \n",
    "        loss.backward()\n",
    "        #to do a one-step update on our parameter.\n",
    "        optimizer.step()\n",
    "        #Print out the loss periodically. \n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))\n",
    "\n",
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args['cuda']:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += F.mse_loss(output.float(), target.float(), size_average=False).item() # sum up batch loss\n",
    "        # get the index of the max log-probability\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('test_loss: ',test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ed727-a48d-4d1e-babb-0a3bf9ce94a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_X(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_X, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        # output = F.log_softmax(x, dim=1)\n",
    "        return x.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656538b7-b70d-4f25-a3d6-639be94476de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Net_X()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eabc04-ea63-4e93-a804-8fe3bd4833bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Net_X()\n",
    "if args['cuda']:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "for epoch in range(1, 5):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7870d0d-2397-4fbf-811b-ffc4d4b07475",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.Tensor(X_train[:100]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084a0b0-c468-4c43-a924-efc6bc1b820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(d.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e487c-7675-47d1-bdda-56f999c4dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((model(d.cpu()).cpu().detach().numpy() - y_train[:100])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026298d-d7a5-4dda-8cab-be86cd62005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = model.to('cpu')\n",
    "\n",
    "adversary = net_adversary.double() #fc_z_agmm(n_instruments, n_hidden, dropout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f02b5-36dd-49eb-b0cc-ba8128ab5feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mliv.neuralnet import ADeepCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c472a-034d-487b-b8c7-1ae64e709cb1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = ADeepCI(learner, adversary).fit(X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, \n",
    "                  X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z, \n",
    "            learner_l2=1e-4, adversary_l2=1e-4, adversary_norm_reg=1e-4,\n",
    "            learner_lr=0.0001, adversary_lr=0.0001, n_epochs=20, bs=bs, train_learner_every=1, train_adversary_every=4,\n",
    "            ols_weight=0., warm_start=True, logger=None, model_dir='.', device= None, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b71fae-342e-42b8-b6bd-62c19a58007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = model #torch.load(os.path.join(res.model_dir,\"epoch{}\".format(res.n_epochs - 1)))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.scatter(X_2_a_k_t.T.squeeze().cpu().data.numpy(), model_final(X_2_a_k.cpu()).cpu().data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e0df7-e0bc-4bad-95dc-0a80d9bdf053",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean((X_2_a_k_t.T.squeeze().cpu().data.numpy() - model_final(X_2_a_k.cpu()).cpu().data.numpy())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ec110-5f6f-4121-9415-840af5e03a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_2_a_k_t.T.squeeze().cpu().data.numpy(), aa(X_2_a_k_t).cpu().data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7635456c-a698-4ab0-8785-3dabc2c6fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ba91b-99bd-4608-a527-12000628b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = model_final(X_2_a_k).cpu().data.numpy()\n",
    "x = aa(X_2_a_k_t).cpu().data.numpy()\n",
    "\n",
    "print(np.mean((y - x) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c6707-ef9d-49a1-a653-90c9cfd0fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.add_constant(x, prepend=False)\n",
    "\n",
    "# Fit and summarize OLS model\n",
    "mod = sm.OLS(y,x)\n",
    "\n",
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "34752fb930ccda7383b9ea105c0ef5936eec2182d44ee5b0b4b02e4beea6e55f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
