{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Magic functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/notebooks/AdversarialGMM/local_notebooks', '/usr/lib/python39.zip', '/usr/lib/python3.9', '/usr/lib/python3.9/lib-dynload', '', '/usr/local/lib/python3.9/dist-packages', '/usr/lib/python3/dist-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path\n",
    "print(sys.path)\n",
    "sys.path.append('/notebooks/AdversarialGMM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### module imports\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "### import from our files\n",
    "from mliv.dgps import get_data, get_tau_fn, fn_dict\n",
    "from mliv.neuralnet.utilities import log_metrics, plot_results, hyperparam_grid,\\\n",
    "                                     hyperparam_mult_grid, eval_performance\n",
    "from mliv.neuralnet.mnist_dgps import AbstractMNISTxz\n",
    "from mliv.neuralnet import AGMM,KernelLayerMMDGMM\n",
    "from mliv.neuralnet.rbflayer import gaussian, inverse_multiquadric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST DGPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Z_agmm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Z_agmm, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class CNN_Z_kernel(nn.Module):\n",
    "    def __init__(self, g_features=100):\n",
    "        super(CNN_Z_kernel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, g_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 1, 28, 28)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class CNN_X(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_X, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 1, 28, 28)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_z_kernel(n_z, n_hidden, g_features, dropout_p):\n",
    "    FC_Z_kernel = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, g_features),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    return FC_Z_kernel\n",
    "\n",
    "\n",
    "def fc_z_agmm(n_z, n_hidden, dropout_p):\n",
    "    FC_Z_agmm = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_Z_agmm\n",
    "\n",
    "\n",
    "def fc_x(n_t, n_hidden, dropout_p):\n",
    "    FC_X = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_t, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(\n",
    "    X_IMAGE=False,\n",
    "    Z_IMAGE=False,\n",
    "    tau_fn=\"abs\",\n",
    "    n_samples=10000,\n",
    "    n_instruments=2,\n",
    "    iv_strength=0.5,\n",
    "    device=None,\n",
    "):\n",
    "    mnist_dgp = AbstractMNISTxz(X_IMAGE, Z_IMAGE, tau_fn)\n",
    "    n_test = n_samples // 10\n",
    "    n_t = 1\n",
    "\n",
    "    T, Z, Y, G, _ = mnist_dgp.generate_data(\n",
    "        n_samples, tau_fn=tau_fn, n_instruments=n_instruments, iv_strength=iv_strength\n",
    "    )\n",
    "\n",
    "    T_test, Z_test, Y_test, G_test, _ = mnist_dgp.generate_data(\n",
    "        n_test, tau_fn=tau_fn, n_instruments=n_instruments, iv_strength=iv_strength,\n",
    "    )\n",
    "\n",
    "    Z_train, Z_val, T_train, T_val, Y_train, Y_val, G_train, G_val = train_test_split(\n",
    "        Z, T, Y, G, test_size=0.1, shuffle=True\n",
    "    )\n",
    "    Z_train, T_train, Y_train, G_train = map(\n",
    "        lambda x: torch.Tensor(x), (Z_train, T_train, Y_train, G_train)\n",
    "    )\n",
    "    Z_val, T_val, Y_val, G_val = map(\n",
    "        lambda x: torch.Tensor(x).to(device), (Z_val, T_val, Y_val, G_val)\n",
    "    )\n",
    "    Z_test, T_test, Y_test, G_test = map(\n",
    "        lambda x: torch.Tensor(x).to(device), (Z_test, T_test, Y_test, G_test)\n",
    "    )\n",
    "\n",
    "    data_array = []\n",
    "    data_array.append((Z_train, T_train, Y_train, G_train))\n",
    "    data_array.append((Z_val, T_val, Y_val, G_val))\n",
    "    data_array.append((Z_test, T_test, Y_test, G_test))\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Train AGMM and KernelLayerGMM estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train AGMM\n",
    "def train_agmm(\n",
    "    Z_train,\n",
    "    T_train,\n",
    "    Y_train,\n",
    "    G_train,\n",
    "    Z_val,\n",
    "    T_val,\n",
    "    Y_val,\n",
    "    G_val,\n",
    "    T_test,\n",
    "    G_test,\n",
    "    X_IMAGE=False,\n",
    "    Z_IMAGE=False,\n",
    "    n_t=1,\n",
    "    n_instruments=2,\n",
    "    n_hidden=200,\n",
    "    dropout_p=0.1,\n",
    "    learner_lr=1e-4,\n",
    "    adversary_lr=1e-4,\n",
    "    learner_l2=1e-4,\n",
    "    adversary_l2=1e-4,\n",
    "    adversary_norm_reg=1e-4,\n",
    "    n_epochs=100,\n",
    "    batch_size=100,\n",
    "    train_learner_every=1,\n",
    "    train_adversary_every=1,\n",
    "):\n",
    "    if X_IMAGE:\n",
    "        learner = CNN_X()\n",
    "    else:\n",
    "        learner = fc_x(n_t, n_hidden, dropout_p)\n",
    "    if Z_IMAGE:\n",
    "        adversary = CNN_Z_agmm()\n",
    "    else:\n",
    "        adversary = fc_z_agmm(n_instruments, n_hidden, dropout_p)\n",
    "\n",
    "    def logger(learner, adversary, epoch, writer):\n",
    "        if not X_IMAGE:\n",
    "            writer.add_histogram(\"learner\", learner[-1].weight, epoch)\n",
    "        if not Z_IMAGE:\n",
    "            writer.add_histogram(\"adversary\", adversary[-1].weight, epoch)\n",
    "        log_metrics(\n",
    "            Z_val,\n",
    "            T_val,\n",
    "            Y_val,\n",
    "            Z_val,\n",
    "            T_val,\n",
    "            Y_val,\n",
    "            T_test,\n",
    "            learner,\n",
    "            adversary,\n",
    "            epoch,\n",
    "            writer,\n",
    "            true_of_T=G_val,\n",
    "        )\n",
    "\n",
    "    np.random.seed(12356)\n",
    "    print(\"---Hyperparameters---\")\n",
    "    print(\"Learner Learning Rate:\", learner_lr)\n",
    "    print(\"Adversary learning rate:\", adversary_lr)\n",
    "    print(\"Learner_l2:\", learner_l2)\n",
    "    print(\"Adversary_l2:\", adversary_l2)\n",
    "    print(\"Number of epochs:\", n_epochs)\n",
    "    print(\"Batch Size:\", batch_size)\n",
    "    agmm = AGMM(learner, adversary).fit(\n",
    "        Z_train,\n",
    "        T_train,\n",
    "        Y_train,\n",
    "        learner_lr=learner_lr,\n",
    "        adversary_lr=adversary_lr,\n",
    "        learner_l2=learner_l2,\n",
    "        adversary_l2=adversary_l2,\n",
    "        n_epochs=n_epochs,\n",
    "        bs=batch_size,\n",
    "        logger=logger,\n",
    "        model_dir=\"agmm_model\",\n",
    "        device=device,\n",
    "        train_learner_every=train_learner_every,\n",
    "        train_adversary_every=train_adversary_every,\n",
    "    )\n",
    "\n",
    "    return agmm\n",
    "\n",
    "\n",
    "#### Train KernelLayerGMM\n",
    "def train_kernellayergmm(\n",
    "    Z_train,\n",
    "    T_train,\n",
    "    Y_train,\n",
    "    G_train,\n",
    "    Z_val,\n",
    "    T_val,\n",
    "    Y_val,\n",
    "    G_val,\n",
    "    T_test,\n",
    "    G_test,\n",
    "    g_features=100,\n",
    "    kernel_fn=gaussian,\n",
    "    centers=None,\n",
    "    sigmas=None,\n",
    "    X_IMAGE=False,\n",
    "    Z_IMAGE=False,\n",
    "    n_t=1,\n",
    "    n_instruments=2,\n",
    "    n_hidden=200,\n",
    "    dropout_p=0.1,\n",
    "    learner_lr=1e-4,\n",
    "    adversary_lr=1e-4,\n",
    "    learner_l2=1e-4,\n",
    "    adversary_l2=1e-4,\n",
    "    adversary_norm_reg=1e-4,\n",
    "    n_epochs=100,\n",
    "    batch_size=100,\n",
    "    train_learner_every=1,\n",
    "    train_adversary_every=1,\n",
    "):\n",
    "    if X_IMAGE:\n",
    "        learner = CNN_X()\n",
    "    else:\n",
    "        learner = fc_x(n_t, n_hidden, dropout_p)\n",
    "    if Z_IMAGE:\n",
    "        adversary = CNN_Z_kernel(g_features)\n",
    "    else:\n",
    "        adversary = fc_z_kernel(n_instruments, n_hidden, g_features, dropout_p)\n",
    "\n",
    "    def logger(learner, adversary, epoch, writer):\n",
    "        if not X_IMAGE:\n",
    "            writer.add_histogram(\"learner\", learner[-1].weight, epoch)\n",
    "        # if not Z_IMAGE:\n",
    "        #  writer.add_histogram('adversary', adversary[-1].weight, epoch)\n",
    "        writer.add_histogram(\"adversary\", adversary.beta.weight, epoch)\n",
    "        log_metrics(\n",
    "            Z_val,\n",
    "            T_val,\n",
    "            Y_val,\n",
    "            Z_val,\n",
    "            T_val,\n",
    "            Y_val,\n",
    "            T_test,\n",
    "            learner,\n",
    "            adversary,\n",
    "            epoch,\n",
    "            writer,\n",
    "            true_of_T=G_val,\n",
    "        )\n",
    "\n",
    "    np.random.seed(12356)\n",
    "    print(\"---Hyperparameters---\")\n",
    "    print(\"Learner Learning Rate:\", learner_lr)\n",
    "    print(\"Adversary learning rate:\", adversary_lr)\n",
    "    print(\"Learner_l2:\", learner_l2)\n",
    "    print(\"Adversary_l2:\", adversary_l2)\n",
    "    print(\"Number of epochs:\", n_epochs)\n",
    "    print(\"Batch Size:\", batch_size)\n",
    "    print(\"G features\", g_features)\n",
    "    print(\"Number of centers\", n_centers)\n",
    "    print(\"Kernel function\", kernel_fn.__name__)\n",
    "    klayermmdgmm = KernelLayerMMDGMM(\n",
    "        learner,\n",
    "        adversary,\n",
    "        g_features,\n",
    "        n_centers,\n",
    "        kernel_fn,\n",
    "        centers=centers,\n",
    "        sigmas=sigmas,\n",
    "    )\n",
    "    klayermmdgmm.fit(\n",
    "        Z_train,\n",
    "        T_train,\n",
    "        Y_train,\n",
    "        learner_l2=learner_l2,\n",
    "        adversary_l2=adversary_l2,\n",
    "        adversary_norm_reg=adversary_norm_reg,\n",
    "        learner_lr=learner_lr,\n",
    "        adversary_lr=adversary_lr,\n",
    "        n_epochs=n_epochs,\n",
    "        bs=bs,\n",
    "        logger=logger,\n",
    "        model_dir=\"klayer_model\",\n",
    "        device=device,\n",
    "        train_learner_every=train_learner_every,\n",
    "        train_adversary_every=train_adversary_every,\n",
    "    )\n",
    "\n",
    "    return klayermmdgmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z - Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate data\n",
    "X_IMAGE = False\n",
    "Z_IMAGE = True\n",
    "tau_fn = \"abs\"\n",
    "n_samples = 1000\n",
    "n_instruments = 2\n",
    "iv_strength = 0.5\n",
    "data = generate_data(\n",
    "    X_IMAGE=X_IMAGE,\n",
    "    Z_IMAGE=Z_IMAGE,\n",
    "    tau_fn=tau_fn,\n",
    "    n_samples=n_samples,\n",
    "    n_instruments=n_instruments,\n",
    "    iv_strength=iv_strength,\n",
    "    device=device,\n",
    ")\n",
    "(Z_train, T_train, Y_train, G_train) = data[0]\n",
    "(Z_val, T_val, Y_val, G_val) = data[1]\n",
    "(Z_test, T_test, Y_test, G_test) = data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/notebooks/AdversarialGMM/mliv/neuralnet/')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from mliv.neuralnet.agmm_earlystop import AGMMEarlyStop, KernelLossAGMMEarlyStop, CentroidMMDGMMEarlyStop, KernelLayerMMDGMMEarlyStop\n",
    "from mliv.neuralnet.architectures import CNN_Z_agmm, CNN_Z_kernel, CNN_X, CNN_X_bn, fc_z_kernel, fc_z_agmm, fc_x\n",
    "from mliv.neuralnet.utilities import log_metrics, dprint\n",
    "from mliv.neuralnet.rbflayer import gaussian, inverse_multiquadric\n",
    "\n",
    "learner = CNN_X()\n",
    "adversary = CNN_Z_agmm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f720aa8fee0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.TensorDataset(Z_train, T_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# parameters for networks\n",
    "dropout_p = 0.1\n",
    "n_t = 1\n",
    "n_hidden = 200\n",
    "\n",
    "# local hyperparam\n",
    "learner_lr = 1e-4\n",
    "adversary_lr = 1e-4\n",
    "learner_l2 = 1e-4\n",
    "adversary_l2 = 1e-4\n",
    "adversary_norm_reg = 1e-4\n",
    "n_epochs = 1\n",
    "bs = 100\n",
    "\n",
    "batch_size = 100\n",
    "train_learner_every = 1\n",
    "train_adversary_every = 1\n",
    "\n",
    "def logger(learner, adversary, epoch, writer):\n",
    "        if not X_IMAGE:\n",
    "            writer.add_histogram(\"learner\", learner[-1].weight, epoch)\n",
    "        if not Z_IMAGE:\n",
    "            writer.add_histogram(\"adversary\", adversary[-1].weight, epoch)\n",
    "        log_metrics(\n",
    "            Z_val,\n",
    "            T_val,\n",
    "            Y_val,\n",
    "            Z_val,\n",
    "            T_val,\n",
    "            Y_val,\n",
    "            T_test,\n",
    "            learner,\n",
    "            adversary,\n",
    "            epoch,\n",
    "            writer,\n",
    "            true_of_T=G_val,\n",
    "        )\n",
    "\n",
    "AGMMEarlyStop(learner, adversary).fit(\n",
    "        Z_train,\n",
    "        T_train,\n",
    "        Y_train,\n",
    "        Z_train,\n",
    "        T_train,\n",
    "        Y_train,\n",
    "        learner_lr=learner_lr,\n",
    "        adversary_lr=adversary_lr,\n",
    "        learner_l2=learner_l2,\n",
    "        adversary_l2=adversary_l2,\n",
    "        n_epochs=n_epochs,\n",
    "        bs=batch_size,\n",
    "        logger=logger,\n",
    "        model_dir=\"agmm_model\",\n",
    "        device=device,\n",
    "        train_learner_every=train_learner_every,\n",
    "        train_adversary_every=train_adversary_every,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train AGMM - Z image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Hyperparameters---\n",
      "Learner Learning Rate: 0.0001\n",
      "Adversary learning rate: 0.0001\n",
      "Learner_l2: 0.0001\n",
      "Adversary_l2: 0.0001\n",
      "Number of epochs: 1\n",
      "Batch Size: 100\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mtrain_agmm\u001b[0;34m(Z_train, T_train, Y_train, G_train, Z_val, T_val, Y_val, G_val, T_test, G_test, X_IMAGE, Z_IMAGE, n_t, n_instruments, n_hidden, dropout_p, learner_lr, adversary_lr, learner_l2, adversary_l2, adversary_norm_reg, n_epochs, batch_size, train_learner_every, train_adversary_every)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of epochs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_epochs)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch Size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_size)\n\u001b[0;32m---> 66\u001b[0m agmm \u001b[38;5;241m=\u001b[39m \u001b[43mAGMM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversary\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mZ_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mT_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearner_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearner_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43madversary_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madversary_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearner_l2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearner_l2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43madversary_l2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madversary_l2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magmm_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_learner_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_learner_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_adversary_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_adversary_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m agmm\n",
      "File \u001b[0;32m/notebooks/AdversarialGMM/mliv/neuralnet/agmm.py:137\u001b[0m, in \u001b[0;36m_BaseSupLossAGMM.fit\u001b[0;34m(self, Z, T, Y, learner_l2, adversary_l2, adversary_norm_reg, learner_lr, adversary_lr, n_epochs, bs, train_learner_every, train_adversary_every, ols_weight, warm_start, logger, model_dir, device, verbose)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, Z, T, Y,\n\u001b[1;32m    113\u001b[0m         learner_l2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, adversary_l2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, adversary_norm_reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m,\n\u001b[1;32m    114\u001b[0m         learner_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, adversary_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, n_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, train_learner_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, train_adversary_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    115\u001b[0m         ols_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, warm_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, model_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    model_dir : folder where to store the learned models after every epoch\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     Z, T, Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlearner_l2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversary_l2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversary_norm_reg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlearner_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversary_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_learner_every\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_adversary_every\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mwarm_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/notebooks/AdversarialGMM/mliv/neuralnet/agmm.py:62\u001b[0m, in \u001b[0;36m_BaseAGMM._pretrain\u001b[0;34m(self, Z, T, Y, learner_l2, adversary_l2, adversary_norm_reg, learner_lr, adversary_lr, n_epochs, bs, train_learner_every, train_adversary_every, warm_start, logger, model_dir, device, verbose, add_sample_inds)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_ds \u001b[38;5;241m=\u001b[39m TensorDataset(Z, T, Y)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dl \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_ds, batch_size\u001b[38;5;241m=\u001b[39mbs, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madversary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madversary\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m warm_start:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parameters for networks\n",
    "dropout_p = 0.1\n",
    "n_t = 1\n",
    "n_hidden = 200\n",
    "\n",
    "# local hyperparam\n",
    "learner_lr = 1e-4\n",
    "adversary_lr = 1e-4\n",
    "learner_l2 = 1e-4\n",
    "adversary_l2 = 1e-4\n",
    "adversary_norm_reg = 1e-4\n",
    "n_epochs = 1\n",
    "bs = 100\n",
    "agmm = train_agmm(Z_train, T_train, Y_train, G_train, Z_val, T_val, Y_val, G_val, T_test, G_test,\n",
    "                  X_IMAGE=False, Z_IMAGE=True, n_t=n_t, n_instruments=n_instruments,\n",
    "                  n_hidden=n_hidden, dropout_p=dropout_p, learner_lr=learner_lr, adversary_lr=adversary_lr,\n",
    "                  learner_l2=learner_l2, adversary_l2=adversary_l2, adversary_norm_reg=adversary_norm_reg,\n",
    "                  n_epochs=n_epochs, batch_size=bs)\n",
    "\n",
    "\n",
    "plot_results(agmm, T_test, true_of_T_test=G_test)\n",
    "eval_performance(agmm,T_test, true_of_T_test=G_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Kernel GMM - Z image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_p = 0.1  # for dropout\n",
    "n_t = 1  # number of treatments\n",
    "n_hidden = 200\n",
    "\n",
    "# For any method that use a projection of z into features g(z)\n",
    "g_features = 100\n",
    "n_centers = 100\n",
    "sigma = 2.0 / g_features\n",
    "# The kernel function\n",
    "kernel_fn = gaussian\n",
    "centers = np.random.uniform(-4, 4, size=(n_centers, 100))\n",
    "sigmas = np.ones((n_centers,)) * sigma\n",
    "\n",
    "# local hyperparam\n",
    "learner_lr = 1e-4\n",
    "adversary_lr = 1e-4\n",
    "learner_l2 = 1e-4\n",
    "adversary_l2 = 1e-4\n",
    "adversary_norm_reg = 1e-4\n",
    "n_epochs = 1\n",
    "bs = 100\n",
    "\n",
    "klayermmdgmm = train_kernellayergmm(\n",
    "    Z_train,\n",
    "    T_train,\n",
    "    Y_train,\n",
    "    G_train,\n",
    "    Z_val,\n",
    "    T_val,\n",
    "    Y_val,\n",
    "    G_val,\n",
    "    T_test,\n",
    "    G_test,\n",
    "    g_features=g_features,\n",
    "    kernel_fn=kernel_fn,\n",
    "    centers=centers,\n",
    "    sigmas=sigmas,\n",
    "    X_IMAGE=False,\n",
    "    Z_IMAGE=True,\n",
    "    n_t=n_t,\n",
    "    n_instruments=n_instruments,\n",
    "    n_hidden=n_hidden,\n",
    "    dropout_p=dropout_p,\n",
    "    learner_lr=learner_lr,\n",
    "    adversary_lr=adversary_lr,\n",
    "    learner_l2=learner_l2,\n",
    "    adversary_l2=adversary_l2,\n",
    "    adversary_norm_reg=adversary_norm_reg,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=bs,\n",
    ")\n",
    "\n",
    "plot_results(klayermmdgmm, T_test, true_of_T_test=G_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X - Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate Data\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "X_IMAGE = True\n",
    "Z_IMAGE = False\n",
    "tau_fn = \"abs\"\n",
    "n_samples = 20000\n",
    "n_instruments = 1  # need to keep this to 1 for now. some bug in the way Bennett et al generate their data.\n",
    "iv_strength = 0.5\n",
    "data = generate_data(\n",
    "    X_IMAGE=X_IMAGE,\n",
    "    Z_IMAGE=Z_IMAGE,\n",
    "    tau_fn=tau_fn,\n",
    "    n_samples=n_samples,\n",
    "    n_instruments=n_instruments,\n",
    "    iv_strength=iv_strength,\n",
    "    device=device,\n",
    ")\n",
    "(Z_train, T_train, Y_train, G_train) = data[0]\n",
    "(Z_val, T_val, Y_val, G_val) = data[1]\n",
    "(Z_test, T_test, Y_test, G_test) = data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train AGMM - X image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train AGMM\n",
    "#%%time\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#  torch.cuda.empty_cache()\n",
    "p = 0.1  # for dropout\n",
    "n_t = 1  # number of treatments\n",
    "n_hidden = 200\n",
    "\n",
    "# local hyperparam\n",
    "learner_lr = 1e-5\n",
    "adversary_lr = 1e-4\n",
    "learner_l2 = 1e-4\n",
    "adversary_l2 = 1e-4\n",
    "adversary_norm_reg = 1e-4\n",
    "n_epochs = 1\n",
    "bs = 100\n",
    "train_learner_every = 1\n",
    "train_adversary_every = 1\n",
    "\n",
    "agmm = train_agmm(\n",
    "    Z_train,\n",
    "    T_train,\n",
    "    Y_train,\n",
    "    G_train,\n",
    "    Z_val,\n",
    "    T_val,\n",
    "    Y_val,\n",
    "    G_val,\n",
    "    T_test,\n",
    "    G_test,\n",
    "    X_IMAGE=X_IMAGE,\n",
    "    Z_IMAGE=Z_IMAGE,\n",
    "    n_t=n_t,\n",
    "    n_instruments=n_instruments,\n",
    "    n_hidden=n_hidden,\n",
    "    dropout_p=dropout_p,\n",
    "    learner_lr=learner_lr,\n",
    "    adversary_lr=adversary_lr,\n",
    "    learner_l2=learner_l2,\n",
    "    adversary_l2=adversary_l2,\n",
    "    adversary_norm_reg=adversary_norm_reg,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=bs,\n",
    "    train_learner_every=train_learner_every,\n",
    "    train_adversary_every=train_adversary_every,\n",
    ")\n",
    "\n",
    "eval_performance(agmm, T_test, true_of_T_test=G_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Kernel GMM - X image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use KernelLayerGMM for DGP 2: only X image\n",
    "\n",
    "# For any method that use a projection of z into features g(z)\n",
    "g_features = 100\n",
    "n_centers = 100\n",
    "sigma = 2.0 / g_features\n",
    "# The kernel function\n",
    "kernel_fn = gaussian\n",
    "\n",
    "centers = np.random.uniform(-4, 4, size=(n_centers, 100))\n",
    "sigmas = np.ones((n_centers,)) * sigma\n",
    "\n",
    "dropout_p = 0.1  # for dropout\n",
    "n_t = 1  # number of treatments\n",
    "n_hidden = 200\n",
    "# local hyperparam\n",
    "learner_lr = 1e-5\n",
    "adversary_lr = 1e-4\n",
    "learner_l2 = 1e-4\n",
    "adversary_l2 = 1e-4\n",
    "adversary_norm_reg = 1e-4\n",
    "n_epochs = 1\n",
    "bs = 100\n",
    "train_learner_every = 1\n",
    "train_adversary_every = 1\n",
    "\n",
    "klayermmdgmm = train_kernellayergmm(\n",
    "    Z_train,\n",
    "    T_train,\n",
    "    Y_train,\n",
    "    G_train,\n",
    "    Z_val,\n",
    "    T_val,\n",
    "    Y_val,\n",
    "    G_val,\n",
    "    T_test,\n",
    "    G_test,\n",
    "    g_features=g_features,\n",
    "    kernel_fn=kernel_fn,\n",
    "    centers=centers,\n",
    "    sigmas=sigmas,\n",
    "    X_IMAGE=X_IMAGE,\n",
    "    Z_IMAGE=Z_IMAGE,\n",
    "    n_t=n_t,\n",
    "    n_instruments=n_instruments,\n",
    "    n_hidden=n_hidden,\n",
    "    dropout_p=dropout_p,\n",
    "    learner_lr=learner_lr,\n",
    "    adversary_lr=adversary_lr,\n",
    "    learner_l2=learner_l2,\n",
    "    adversary_l2=adversary_l2,\n",
    "    adversary_norm_reg=adversary_norm_reg,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=bs,\n",
    "    train_learner_every=train_learner_every,\n",
    "    train_adversary_every=train_adversary_every,\n",
    ")\n",
    "\n",
    "eval_performance(klayermmdgmm, T_test, true_of_T_test=G_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X and Z - Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate Data\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "X_IMAGE = True\n",
    "Z_IMAGE = True\n",
    "tau_fn = \"abs\"\n",
    "n_samples = 20000\n",
    "n_instruments = 2\n",
    "iv_strength = 0.5\n",
    "data = generate_data(\n",
    "    X_IMAGE=X_IMAGE,\n",
    "    Z_IMAGE=Z_IMAGE,\n",
    "    tau_fn=tau_fn,\n",
    "    n_samples=n_samples,\n",
    "    n_instruments=n_instruments,\n",
    "    iv_strength=iv_strength,\n",
    "    device=device,\n",
    ")\n",
    "(Z_train, T_train, Y_train, G_train) = data[0]\n",
    "(Z_val, T_val, Y_val, G_val) = data[1]\n",
    "(Z_test, T_test, Y_test, G_test) = data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train AGMM - X and Z images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "dropout_p = 0.1  # for dropout\n",
    "n_t = 1  # number of treatments\n",
    "n_hidden = 200\n",
    "\n",
    "# local hyperparam\n",
    "learner_lr = 1e-4\n",
    "adversary_lr = 1e-4\n",
    "learner_l2 = 1e-4\n",
    "adversary_l2 = 1e-4\n",
    "adversary_norm_reg = 1e-4\n",
    "n_epochs = 1\n",
    "bs = 100\n",
    "\n",
    "\n",
    "agmm = train_agmm(\n",
    "    Z_train,\n",
    "    T_train,\n",
    "    Y_train,\n",
    "    G_train,\n",
    "    Z_val,\n",
    "    T_val,\n",
    "    Y_val,\n",
    "    G_val,\n",
    "    T_test,\n",
    "    G_test,\n",
    "    X_IMAGE=X_IMAGE,\n",
    "    Z_IMAGE=Z_IMAGE,\n",
    "    n_t=n_t,\n",
    "    n_instruments=n_instruments,\n",
    "    n_hidden=n_hidden,\n",
    "    dropout_p=dropout_p,\n",
    "    learner_lr=learner_lr,\n",
    "    adversary_lr=adversary_lr,\n",
    "    learner_l2=learner_l2,\n",
    "    adversary_l2=adversary_l2,\n",
    "    adversary_norm_reg=adversary_norm_reg,\n",
    "    n_epochs=n_epochs,\n",
    "    batch_size=bs,\n",
    "    train_learner_every=train_learner_every,\n",
    "    train_adversary_every=train_adversary_every,\n",
    ")\n",
    "\n",
    "eval_performance(agmm, T_test, true_of_T_test=G_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Kernel GMM - X and Z images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# For any method that use a projection of z into features g(z)\n",
    "g_features = 100\n",
    "n_centers = 100\n",
    "sigma = 2.0 / g_features\n",
    "# The kernel function\n",
    "kernel_fn = gaussian\n",
    "\n",
    "centers = np.random.uniform(-4, 4, size=(n_centers, 100))\n",
    "sigmas = np.ones((n_centers,)) * sigma\n",
    "\n",
    "dropout_p = 0.1 # for dropout\n",
    "n_t = 1 # number of treatments\n",
    "n_hidden = 200\n",
    "\n",
    "# training hyperparameters\n",
    "learner_lr = 1e-5\n",
    "adversary_lr = 1e-4\n",
    "learner_l2 = 1e-4\n",
    "adversary_l2 = 1e-4\n",
    "adversary_norm_reg = 1e-4\n",
    "n_epochs = 1\n",
    "bs = 100\n",
    "train_learner_every = 1\n",
    "train_adversary_every = 1\n",
    "\n",
    "\n",
    "klayermmdgmm = train_kernellayergmm(Z_train, T_train, Y_train, G_train,\n",
    "                                    Z_val, T_val, Y_val, G_val, T_test, G_test,\n",
    "                                    g_features=g_features, kernel_fn=kernel_fn,\n",
    "                                    centers=centers, sigmas=sigmas,\n",
    "                                    X_IMAGE=X_IMAGE, Z_IMAGE=Z_IMAGE, n_t=n_t,\n",
    "                                    n_instruments=n_instruments,\n",
    "                                    n_hidden=n_hidden, dropout_p=dropout_p, \n",
    "                                    learner_lr=learner_lr, adversary_lr=adversary_lr,\n",
    "                                    learner_l2=learner_l2, adversary_l2=adversary_l2,\n",
    "                                    adversary_norm_reg=adversary_norm_reg,\n",
    "                                    n_epochs=n_epochs, batch_size=bs,\n",
    "                                    train_learner_every=train_learner_every,\n",
    "                                    train_adversary_every=train_adversary_every)\n",
    "\n",
    "eval_performance(klayermmdgmm,T_test, true_of_T_test=G_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Experiments at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgp_to_bools(dgp_str):\n",
    "    x = False\n",
    "    z = False\n",
    "    if dgp_str=='mnist_x':\n",
    "        x = True\n",
    "    elif dgp_str== 'mnist_z':\n",
    "        z = True\n",
    "    elif dgp_str=='mnist_xz':\n",
    "        x = True\n",
    "        z = True\n",
    "    return x,z\n",
    "\n",
    "def experiment(dgp,iv_strength,tau_fn,num_data,est):\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"Experiment\")\n",
    "    print(dgp,est,iv_strength,tau_fn)\n",
    "\n",
    "    # Fixed hyper-parameters - can vary these too\n",
    "    # params for kernelgmm\n",
    "    g_features = 100\n",
    "    kernel_fn = gaussian\n",
    "    centers = np.random.uniform(-4, 4, size=(n_centers, 100))\n",
    "    sigmas = np.ones((n_centers,)) * sigma\n",
    "\n",
    "    # arch params\n",
    "    dropout_p = 0.1 # for dropout\n",
    "    n_t = 1 # number of treatments\n",
    "    n_hidden = 200\n",
    "\n",
    "    # training params\n",
    "    learner_lr = 1e-5\n",
    "    adversary_lr = 1e-4\n",
    "    learner_l2 = 1e-4\n",
    "    adversary_l2 = 1e-4\n",
    "    adversary_norm_reg = 1e-4\n",
    "    n_epochs = 1\n",
    "    bs = 100\n",
    "    train_learner_every = 1\n",
    "    train_adversary_every = 1\n",
    "\n",
    "    # generate data\n",
    "    X_IMAGE,Z_IMAGE = dgp_to_bools(dgp)\n",
    "    n_instruments = 1\n",
    "    data = generate_data(X_IMAGE=X_IMAGE, Z_IMAGE=Z_IMAGE, tau_fn=tau_fn, n_samples=num_data,\n",
    "                    n_instruments=n_instruments, iv_strength=iv_strength, device=device)\n",
    "    (Z_train, T_train, Y_train, G_train) = data[0]\n",
    "    (Z_val, T_val, Y_val, G_val) = data[1]\n",
    "    (Z_test, T_test, Y_test, G_test) = data[2]\n",
    "\n",
    "    if est=='AGMM':\n",
    "        estimator = train_agmm(Z_train, T_train, Y_train, G_train,\n",
    "                               Z_val, T_val, Y_val, G_val, T_test, G_test,\n",
    "                               X_IMAGE=X_IMAGE, Z_IMAGE=Z_IMAGE, n_t=n_t,\n",
    "                               n_instruments=n_instruments,\n",
    "                               n_hidden=n_hidden, dropout_p=dropout_p,\n",
    "                               learner_lr=learner_lr, adversary_lr=adversary_lr,\n",
    "                               learner_l2=learner_l2, adversary_l2=adversary_l2,\n",
    "                               adversary_norm_reg=adversary_norm_reg, n_epochs=n_epochs,\n",
    "                               batch_size=bs,\n",
    "                               train_learner_every=train_learner_every,\n",
    "                               train_adversary_every=train_adversary_every)\n",
    "\n",
    "    elif est=='KernelLayerMMDGMM':\n",
    "        estimator = train_kernellayergmm(Z_train, T_train, Y_train, G_train,\n",
    "                                         Z_val, T_val, Y_val, G_val, T_test, G_test,\n",
    "                                         g_features=g_features, kernel_fn=kernel_fn,\n",
    "                                         centers=centers, sigmas=sigmas,\n",
    "                                         X_IMAGE=X_IMAGE, Z_IMAGE=Z_IMAGE, n_t=n_t,\n",
    "                                         n_instruments=n_instruments,\n",
    "                                         n_hidden=n_hidden, dropout_p=dropout_p,\n",
    "                                         learner_lr=learner_lr, adversary_lr=adversary_lr,\n",
    "                                         learner_l2=learner_l2, adversary_l2=adversary_l2,\n",
    "                                         adversary_norm_reg=adversary_norm_reg,\n",
    "                                         n_epochs=n_epochs, batch_size=bs,\n",
    "                                         train_learner_every=train_learner_every,\n",
    "                                         train_adversary_every=train_adversary_every)\n",
    "\n",
    "    results = eval_performance(estimator, T_test, true_of_T_test=G_test)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte-Carlo Loop\n",
    "# 1. loop over functions\n",
    "# 2. loop over instrument strengths\n",
    "# 3. loop over estimators\n",
    "# 4. loop over dgps\n",
    "\n",
    "tau_fns = [\"abs\", \"sin\", \"2dpoly\", \"rand_pw\", \"3dpoly\"]\n",
    "iv_strength = [0.2, 0.5, 0.8]\n",
    "estimators = [\"AGMM\", \"KernelLayerMMDGMM\"]\n",
    "dgps = [\"z_image\", \"x_image\", \"xz_image\"]\n",
    "num_datas = [1000]\n",
    "\n",
    "\n",
    "hyperparams = list(itertools.product(tau_fns, iv_strength, dgps, num_datas, estimators))\n",
    "result_dict = {}\n",
    "\n",
    "for (tau_fn, iv_strength, dgp, num_data, est) in hyperparams:\n",
    "    results = experiment(dgp, iv_strength, tau_fn, num_data, est)\n",
    "    result_dict[(tau_fn, iv_strength, dgp, num_data, est)] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MNIST_Experiments.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
