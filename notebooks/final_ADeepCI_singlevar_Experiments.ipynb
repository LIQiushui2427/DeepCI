{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d77d2b9-1d2b-4d84-8c0e-2b51d3a546e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\\research\\DeepCI-master\\notebooks\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "seedNum = 888\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "tf.random.set_seed(seedNum)\n",
    "np.random.seed(seedNum)\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import sys, os\n",
    "print(os.getcwd())\n",
    "os.chdir('Y:\\\\research\\\\DeepCI-master\\\\notebooks')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "### import from our files\n",
    "from model.adeepci_score import ADeepCI\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# !pip install statsmodels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c249b24-2bc8-4a50-a34c-6b9b1a3e9e9d",
   "metadata": {},
   "source": [
    "# use the normal \"scale\" estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e330df4-e41d-4c1d-8c2c-02698a6d616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_epochs = 60\n",
    "# bs = 2\n",
    "n_epochs = 200 #80\n",
    "bs = 50\n",
    "J = 10\n",
    "rho = 0.2\n",
    "func_run = \"step\"\n",
    "epoch = 1  # 1 \n",
    "with open(\"./val.log\", 'a', encoding='utf-8') as f:\n",
    "    f.write(\"--------------------------------\\n\")\n",
    "    f.write(\"config:\\n\")\n",
    "    f.write(\"epoch: %d\\n\" % epoch)\n",
    "    f.write(\"func_run: %s\\n\" % func_run)\n",
    "    f.write(\"n_epochs: %d\\n\" % n_epochs)\n",
    "    f.write(\"bs: %d\\n\" % bs)\n",
    "    f.write(\"J: %d\\n\" % J)\n",
    "    f.write(\"rho: %f\\n\" % rho)\n",
    "    f.write(\"--------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5dc0866-6082-45f2-b228-629307f360e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function(func_str):\n",
    "    if func_str == \"abs\":\n",
    "        return (lambda x: ((np.abs(np.abs(x)-2)-1.5)/1).flatten(), \n",
    "                lambda x: ((torch.abs(torch.abs(x)-2)-1.5)/1).flatten())\n",
    "    elif func_str == \"log\":\n",
    "        return (lambda x: 2*np.log(np.abs(x)).flatten(), \n",
    "                lambda x: 2*torch.log(torch.abs(x)).flatten())\n",
    "    elif func_str == \"sin\":\n",
    "        return (lambda x: np.sin(x).flatten(), \n",
    "                lambda x: torch.sin(x).flatten())\n",
    "    else:\n",
    "        return (lambda x: np.sign(np.abs(np.abs(x)-5)-2).flatten(), \n",
    "                lambda x: torch.sign(torch.abs(torch.abs(x)-5)-2).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afb4ee77-a552-4026-9dac-14abf4b70b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simdata(NUM_I,seed,func,rho): #a = y_train/test, b = X_train/test\n",
    "    \n",
    "    kk = 5\n",
    "    \n",
    "    np.random.seed(seed)    \n",
    "    X_1_a_j = [] \n",
    "    X_2_a_j = [] \n",
    "    X_1_a_k = [] \n",
    "    X_2_a_k = [] \n",
    "    X_1_b_j = [] \n",
    "    X_2_b_j = [] \n",
    "    X_1_b_k = [] \n",
    "    X_2_b_k = []\n",
    "    Z       = []\n",
    "    for i in tqdm(range(0,NUM_I)):\n",
    "        #J = np.random.randint(4,10) # number of choice\n",
    "        \n",
    "        X_1_a = np.random.uniform(-1,1,J) #customer a\n",
    "        X_2_a = np.random.uniform(-kk,kk,J)  #customer a # -3 to 3 work well\n",
    "        X_1_b = np.random.uniform(-1,1,J) #customer b\n",
    "        X_2_b = np.random.uniform(-kk,kk,J) #customer b\n",
    "        \n",
    "        xi  = np.random.normal(0,0.5,J)    # same across all customers\n",
    "        \n",
    "        X_2_a = X_2_a + rho*xi  #customer a endogeneity\n",
    "        \n",
    "        X_2_b = X_2_b + rho*xi  #customer b endogeneity\n",
    "        \n",
    "        u_a   = X_1_a + 2*func(X_2_a) + xi + np.random.normal(0,3,J) # \\epsilon_{a} # originally 0.1\n",
    "        u_b   = X_1_b + 2*func(X_2_b) + xi + np.random.normal(0,3,J) # \\epsilon_{b}\n",
    "        choice_j = np.argmax(u_a) # return the index of product in the sample that customer a chose, we assume customer a as choose j\n",
    "\n",
    "        choice_k = np.argmax(u_b) # return the index of product in the sample that customer b chose, we assume customer b as choose k\n",
    "               \n",
    "        if choice_j == choice_k:\n",
    "            continue\n",
    "        else:  \n",
    "\n",
    "            X_1_a_j.append(X_1_a[choice_j])\n",
    "            X_2_a_j.append(X_2_a[choice_j])\n",
    "            X_1_a_k.append(X_1_a[choice_k])\n",
    "            X_2_a_k.append(X_2_a[choice_k])\n",
    "            \n",
    "            X_1_b_j.append(X_1_b[choice_j]) \n",
    "            X_2_b_j.append(X_2_b[choice_j]) \n",
    "            X_1_b_k.append(X_1_b[choice_k]) \n",
    "            X_2_b_k.append(X_2_b[choice_k]) \n",
    "            Z.append(np.array([X_1_a[choice_j], X_2_a[choice_j], X_1_a[choice_k], X_2_a[choice_k], \n",
    "                                   X_1_b[choice_j], X_2_b[choice_j], X_1_b[choice_k], X_2_b[choice_k]]))\n",
    "    \n",
    "    return torch.Tensor(X_1_a_j).reshape((-1,1)).double(), torch.Tensor(X_2_a_j).reshape((-1,1)).double(), \\\n",
    "torch.Tensor(X_1_a_k).reshape((-1,1)).double(), torch.Tensor(X_2_a_k).reshape((-1,1)).double(), torch.Tensor(X_1_b_j).reshape((-1,1)).double(), \\\n",
    "torch.Tensor(X_2_b_j).reshape((-1,1)).double(), torch.Tensor(X_1_b_k).reshape((-1,1)).double(), torch.Tensor(X_2_b_k).reshape((-1,1)).double(), \\\n",
    "torch.tensor(Z, dtype=torch.float64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16ad8027-3000-4929-b8d3-47a42661db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa,bb = get_function(func_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a38b07e4-f0c0-4b72-96d6-925250d5953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 20487.26it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(19104)\n",
    "X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z = Simdata(10000,2,aa,rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0a0f2d5-b1d7-4b6d-a85d-85b39a1c7681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = (X_1_a_j[0:100]+2*torch.unsqueeze(aa(X_2_a_j[0:100]),-1))-(X_1_a_k[0:100]+2*torch.unsqueeze(aa(X_2_a_k[0:100]),-1))\n",
    "torch.sum(tmp<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a82e63c-963d-4dec-9ace-4f6d403f0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Z_agmm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Z_agmm, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "class CNN_Z_kernel(nn.Module):\n",
    "    def __init__(self, g_features=100):\n",
    "        super(CNN_Z_kernel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, g_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output.squeeze()\n",
    "\n",
    "\n",
    "class CNN_X(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_X, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 1, 28, 28)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = x  # F.log_softmax(x, dim=1)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e893ec27-77fd-4945-a9ee-f4ae0fb6a6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_z_kernel(n_z, n_hidden, g_features, dropout_p):\n",
    "    FC_Z_kernel = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, g_features),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "    return FC_Z_kernel\n",
    "\n",
    "\n",
    "def fc_z_agmm(n_z, n_hidden, dropout_p):\n",
    "    FC_Z_agmm = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_z, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_Z_agmm\n",
    "\n",
    "\n",
    "def fc_x(n_t, n_hidden, dropout_p):\n",
    "    FC_X = nn.Sequential(\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_t, n_hidden),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(p=dropout_p),\n",
    "        nn.Linear(n_hidden, 1),\n",
    "    )\n",
    "    return FC_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5aab8430-e3fa-4560-a3da-8e0178dbdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 500\n",
    "n_hidden = 300\n",
    "n_instruments = 1\n",
    "dropout_p = 0.1\n",
    "\n",
    "\n",
    "class CNN_X(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_X, self).__init__()\n",
    "        self.conv1 = nn.Linear(1, k)\n",
    "        self.conv2 = nn.Linear(k, 200)\n",
    "        self.conv3 = nn.Linear(200, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        #x = F.relu(x)\n",
    "        output = 1.5*torch.nn.functional.tanh(x)\n",
    "        return output.squeeze()\n",
    "    \n",
    "\n",
    "if func_run == \"abs\":\n",
    "    net_learner1 = CNN_X()\n",
    "else:\n",
    "    net_learner1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, k),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(k, 200),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(200, 2),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(2, 1),\n",
    "            torch.nn.Tanh(),\n",
    "            )\n",
    "        \n",
    "\n",
    "net_learner2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, k),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(k, 200),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(200, 1),\n",
    "            )\n",
    "\n",
    "\n",
    "learner = nn.Sequential(nn.Dropout(p=dropout_p), nn.Linear(k, n_hidden), nn.LeakyReLU(),\n",
    "                       nn.Dropout(p=dropout_p), nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "                       nn.Dropout(p=dropout_p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "adversary_fn = nn.Sequential(nn.Dropout(p=dropout_p), nn.Linear(k, n_hidden), nn.LeakyReLU(),\n",
    "                            nn.Dropout(p=dropout_p), nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "                            nn.Dropout(p=dropout_p), nn.Linear(n_hidden, 1))\n",
    "\n",
    "net_adversary = torch.nn.Sequential(nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(8, k),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),                        \n",
    "            torch.nn.Linear(k, 200), #200\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),                        \n",
    "            torch.nn.Linear(200, 1),\n",
    "            )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5026298d-d7a5-4dda-8cab-be86cd62005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner1 = net_learner1.double()\n",
    "\n",
    "learner2 = net_learner2.double()\n",
    "\n",
    "adversary = net_adversary.double() #fc_z_agmm(n_instruments, n_hidden, dropout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f481d19-7de8-4794-b01d-aac7f308be0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# res1 = ADeepCI(learner1, adversary).fit(X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, \n",
    "#                   X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z, \n",
    "#                   learner_l2=1e-3, adversary_l2=1e-4, adversary_norm_reg=1e-3,\n",
    "#                   learner_lr=0.001, adversary_lr=0.001, n_epochs=n_epochs, bs=bs, train_learner_every=1, train_adversary_every=1,\n",
    "#                   ols_weight=0.1, warm_start=False, logger=None, model_dir='.', device=None, verbose=False)\n",
    "\n",
    "# model_final1 = torch.load(os.path.join(res1.model_dir,\"epoch{}\".format(res1.n_epochs-1)))\n",
    "\n",
    "# res2 = ADeepCI(learner2, adversary).fit(X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, \n",
    "#             X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z, \n",
    "#             learner_l2=1e-3, adversary_l2=1e-4, adversary_norm_reg=1e-3,\n",
    "#             learner_lr=0.001, adversary_lr=0.001, n_epochs=n_epochs, bs=bs, train_learner_every=1, train_adversary_every=1,\n",
    "#             ols_weight=0.1, warm_start=False, logger=None, model_dir='.', device=None, verbose=False)\n",
    "            \n",
    "# model_final2 = torch.load(os.path.join(res2.model_dir,\"epoch{}\".format(res2.n_epochs - 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f07b9098-991b-40be-a13a-7b2dc83f9eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_2_a_k.T.squeeze().cpu().data.numpy(), aa(X_2_a_k).cpu().data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "871c54ad-2b82-4d0d-9f34-d958c4346925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 20279.13it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(19104+1)\n",
    "X_1_a_j_test, X_2_a_j_test, X_1_a_k_test, X_2_a_k_test, X_1_b_j_test, X_2_b_j_test, X_1_b_k_test, X_2_b_k_test, Z_test = Simdata(10000,2,aa,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98fffc74-f5fc-4dde-a45f-7bc7b44e0fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 20828.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learner loss tensor(0.0135, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0088, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1935, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0899, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2155, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1787, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2290, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4226, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1228, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0652, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7674, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0123, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0106, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0087, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.5427, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5322, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1577, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.1744, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0630, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0705, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1272, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0466, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.6069, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.4060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7220, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.2797, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0467, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0741, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1100, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0109, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.1279, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5108, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1090, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4054, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3886, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1159, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2599, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.3641, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8744, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3838, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4225, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2188, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.1436, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5681, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0679, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.3899, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.6512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0328, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0019, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.2583, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.6677, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.8266, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.2889, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3068, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0288, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0578, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9310, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.6534, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3089, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1692, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(8.1228, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(3.1767, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1125, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.9661, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.4806, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2380, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1212, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0153, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.5397, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0938, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5311, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8141, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2210, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0668, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7715, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0050, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0025, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3469, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2629, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.3150, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8858, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1580, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1814, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4685, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2517, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.8931, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(1.4291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1985, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1624, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1410, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.1390, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0241, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5371, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2581, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.7016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0468, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.4985, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8891, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.1338, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.2902, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7170, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1221, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.2056, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2475, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4654, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.6634, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0950, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.6296, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0076, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0028, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3897, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7129, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3402, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(1.6040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2264, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(6.9429, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-2.0051, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4243, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.7891, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.7581, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4746, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0793, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1305, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0440, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1786, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5347, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0490, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.1470, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.0255, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0787, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0476, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1710, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0524, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.3511, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1171, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7443, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4604, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.0203, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.3251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.6365, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0858, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1124, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.3240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1009, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0751, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0562, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0002, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1100, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0300, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1191, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0981, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0125, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1593, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0337, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0044, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2959, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3620, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5846, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3390, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1527, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.1902, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.5176, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7720, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4875, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2865, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.4759, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(9.3367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.3532, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.6752, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(8.0656, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.3920, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5356, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3377, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2547, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4792, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.6609, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4731, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1308, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(5.1530, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(1.9124, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.4017, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.4855, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0907, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0359, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4010, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.5311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2219, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(4.3483, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8307, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3851, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8295, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0554, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7015, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.9107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.9620, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.5525, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0382, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0059, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4587, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1671, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8659, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3234, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1727, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2487, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0370, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.8252, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.7279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0832, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0519, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9000, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2777, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0026, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4434, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.2097, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1476, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1161, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.2084, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1812, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1926, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0420, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1231, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4106, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0272, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.2935, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.7282, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2742, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0060, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0532, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.2776, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3094, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3547, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3232, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5421, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.1593, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.4749, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.4571, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.3444, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.5389, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(1.8276, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0021, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4869, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.6869, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8251, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0024, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0063, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.6340, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8318, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.0581, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.5153, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0357, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0217, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5773, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3601, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0084, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0708, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0243, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.0711, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.4735, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0140, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(10.5773, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1752, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0062, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1892, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.0203, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4234, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.8023, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.9014, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0823, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0978, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1003, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0888, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0120, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2597, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0708, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.7101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2869, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7233, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3791, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0071, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4139, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(1.4653, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1695, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0829, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1615, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.1389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1533, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1852, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0016, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.0327, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.5590, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.2343, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.5738, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.7679, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.1231, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.1985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.1290, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2565, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.6098, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1367, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.2185, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(1.5411, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0366, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0270, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.5508, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(22.4908, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0465, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0185, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(5.9337, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3463, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.1037, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5465, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2868, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1655, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0145, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.4626, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.6011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2504, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0693, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0985, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8916, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4443, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2225, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.6380, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2885, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0558, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2725, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2702, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7913, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0651, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0609, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0183, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.5444, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.1951, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0064, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8157, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5556, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2682, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5796, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2461, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0383, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.4060, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1122, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3405, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4932, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(5.2504, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.4386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1185, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1378, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 19602.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learner loss tensor(0.0055, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1535, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1419, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0643, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1342, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2173, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1223, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0588, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0010, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0814, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0286, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7181, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3586, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1241, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1198, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2567, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.1291, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.9060, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7808, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5355, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3576, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2610, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.4003, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5468, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0038, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7403, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.2008, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1259, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0332, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0349, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4847, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3120, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1067, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1632, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0172, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0266, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0543, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9520, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0115, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0358, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0568, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1172, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1479, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.7153, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.7241, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9506, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5755, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1790, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7803, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(1.6922, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1865, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2920, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3097, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.3187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.5519, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2857, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2538, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1218, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0404, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0366, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.9389, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.6505, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.8877, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.2327, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.3502, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.6538, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0436, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0230, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1818, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1849, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1511, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.0867, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1298, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.1069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0923, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5034, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0324, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0710, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2195, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4632, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.4971, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5948, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1891, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0148, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7360, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0042, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0938, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1761, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0585, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4981, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.2654, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8915, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2596, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0711, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0105, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0185, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0608, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.2192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0790, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0979, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.2257, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8640, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.8434, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.3738, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1319, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0589, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2994, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(3.0101, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(5.2031, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.4721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2987, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5664, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0192, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(5.4459, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.5115, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3341, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0933, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0958, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1831, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8904, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4985, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0267, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0105, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0041, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.4488, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2540, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0722, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0281, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9951, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.7726, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.4492, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.7297, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0253, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1279, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1247, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0645, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0054, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1689, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1218, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.6978, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5079, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0303, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0605, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.0662, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2545, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1968, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2394, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0558, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.8156, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.6474, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4366, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4110, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0194, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3370, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.5464, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4478, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3610, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0351, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0179, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0108, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8131, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5872, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3715, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1583, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0074, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0023, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0136, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2691, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2446, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2759, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4104, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.1057, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0167, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0216, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0775, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0256, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.0180, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-2.2159, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3656, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1659, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1018, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0432, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7137, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.5552, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0102, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0118, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0495, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0386, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0213, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.9201, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0317, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0288, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.3828, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.9081, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0684, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1448, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.6026, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0554, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4735, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0318, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0310, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0503, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1223, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4915, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.1730, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.9801, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.3331, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.6392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5732, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3814, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.5716, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4815, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.9800, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.7772, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1178, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1654, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7256, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0160, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.3083, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0686, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1183, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0722, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1808, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4780, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3321, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2247, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1480, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1577, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1075, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8115, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5404, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8204, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0311, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2607, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3004, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0711, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.4174, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.3913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0445, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1357, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1925, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1806, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3346, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1178, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0181, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0162, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1005, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0644, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1296, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0376, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0186, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.4793, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4107, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0545, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0381, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9007, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1426, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3140, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.1040, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.6979, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0137, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0489, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3806, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0088, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0071, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1208, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0945, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0734, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0219, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.0915, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(1.4299, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2660, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1070, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2687, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3780, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0786, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0503, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0945, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0484, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0131, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4916, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0348, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0158, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.5840, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.3240, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0383, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0114, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1551, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0553, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1017, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0372, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.6167, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5269, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.7264, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2941, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1015, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0678, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5088, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1293, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.6368, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4564, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4592, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0135, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0338, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.4485, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-2.2799, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.9498, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-2.2622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0089, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.2224, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2872, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.3251, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4413, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3448, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.1709, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(4.4432, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-2.0329, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.6326, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3974, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.2939, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2033, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1633, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0111, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0901, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.5065, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7925, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.0876, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1234, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1322, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1294, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2548, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7398, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.9294, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2459, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0148, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.2315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1773, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9570, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.4531, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1334, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0667, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9126, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3369, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0119, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0536, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4354, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0142, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7961, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.3516, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0808, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0737, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2705, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1953, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0356, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5615, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0804, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0233, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 20156.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learner loss tensor(0.0047, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0038, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0490, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0447, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2524, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1913, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2580, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0907, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2093, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1375, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4858, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3016, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4367, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3339, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2566, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2204, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0235, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2676, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3023, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4460, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1230, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0912, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3478, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2627, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5436, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4577, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.6078, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5980, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0888, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0424, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0275, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0376, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2608, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0745, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2015, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4917, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7912, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3507, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0133, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0890, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0279, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1250, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2098, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0528, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0666, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1669, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1644, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0925, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1200, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2567, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.2398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1777, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.3602, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.1192, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4523, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3631, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2456, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0482, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0325, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.3441, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3532, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2102, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.4528, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4398, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0657, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0325, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1954, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2564, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.4631, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1009, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0258, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1092, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.4461, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0330, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2066, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0060, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0003, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.8150, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0544, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9128, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1835, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1254, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0438, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0149, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0775, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1462, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1045, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0548, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5597, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4464, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3364, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(9.3338, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.8212, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4850, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3830, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.6452, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.3645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8597, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5011, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.2859, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.8838, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0259, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0863, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0486, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7265, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.7793, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0534, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0180, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.5998, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.2551, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.5720, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.4699, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.6381, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.8494, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1090, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0885, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3326, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2827, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1921, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0515, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1082, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1393, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.9162, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.3482, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0815, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0046, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9217, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5761, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4018, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3373, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1941, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1099, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.6770, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5389, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0434, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0672, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.6680, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.6323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2266, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2307, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0344, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0171, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1377, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0392, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1255, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0156, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.1389, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2216, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0045, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0006, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1616, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2160, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9863, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8770, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2148, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.4203, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2740, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1545, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.8675, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0660, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8049, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4882, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1347, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0275, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8311, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3803, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3002, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(1.4980, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0021, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0401, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7277, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(3.8089, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0113, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1061, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2788, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3013, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1761, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1420, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.9832, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.5135, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0163, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4253, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1686, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1102, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1428, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0653, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1460, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0270, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0618, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.8585, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0379, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2106, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1434, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0461, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0512, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2144, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1400, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1998, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0427, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0263, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.8470, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.6660, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5217, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1766, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.1261, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1291, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8712, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3902, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2466, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2249, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.7530, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.7464, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1892, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0284, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.1793, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.2341, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2996, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1539, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2413, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.8069, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5433, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0491, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0020, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0062, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2423, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0974, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1817, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3037, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2416, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0645, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0248, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0315, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8165, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1471, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4516, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2263, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0024, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.1091, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1541, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0862, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.1798, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8043, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7300, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8622, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2520, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2642, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0461, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0387, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.0783, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.0973, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0919, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0353, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1950, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1050, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1346, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1680, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0521, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0280, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4276, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2766, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1409, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0303, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0282, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0065, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0012, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0093, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2599, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8607, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5286, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(3.6332, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3649, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2323, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0237, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0039, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3030, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3459, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(5.9043, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(2.9886, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.1160, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.1770, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0214, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0374, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9267, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.7304, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0027, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0529, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(6.0520, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(8.6990, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9679, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.6231, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0191, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0488, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2581, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.0909, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0140, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3342, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0157, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(1.3406, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0596, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0032, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8632, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1640, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0629, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0797, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2014, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2768, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.4607, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1832, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.4775, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.0454, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.6710, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1683, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9288, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.6350, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0603, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0625, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0545, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0325, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0076, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0779, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1401, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3194, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.3882, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0956, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1994, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0860, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0174, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0567, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0315, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1964, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0418, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0559, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0328, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0030, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.6379, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.2970, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0727, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1029, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2005, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0129, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7941, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.8890, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1012, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0125, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0962, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0237, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0439, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0526, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.3817, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1119, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.8575, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0133, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7091, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.7481, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.0886, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-1.6754, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(2.2024, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-2.1207, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1786, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1012, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5670, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.2957, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(5.7665, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(17.8346, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1103, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3670, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.2468, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.0208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.9687, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0780, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.5794, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1047, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1286, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.3187, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(3.0388, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.5895, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.9598, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(0.1741, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7596, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(1.2407, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.1262, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.1668, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0807, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0250, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.7605, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.4933, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(1.2849, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.6910, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "learner loss tensor(0.0369, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "adversary loss tensor(-0.0095, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "RMSEs 0.3990239769892063\n",
      "MSEs 0.1600348150937765\n",
      "MAEs 0.2870496877736668\n",
      "MAPEs 28.704968777366677\n",
      "Biases -0.15660265299449505\n",
      "Y shape == X shape: False\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                        -inf\n",
      "Model:                            OLS   Adj. R-squared:                   -inf\n",
      "Method:                 Least Squares   F-statistic:                    -8920.\n",
      "Date:                Fri, 26 May 2023   Prob (F-statistic):               1.00\n",
      "Time:                        14:22:49   Log-Likelihood:             2.6196e+05\n",
      "No. Observations:                8922   AIC:                        -5.239e+05\n",
      "Df Residuals:                    8920   BIC:                        -5.239e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1          4.294e-15   4.57e-16      9.389      0.000     3.4e-15    5.19e-15\n",
      "const          1.0000   4.57e-16   2.19e+15      0.000       1.000       1.000\n",
      "==============================================================================\n",
      "Omnibus:                    31792.245   Durbin-Watson:                   0.020\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1488.068\n",
      "Skew:                           0.232   Prob(JB):                         0.00\n",
      "Kurtosis:                       1.054   Cond. No.                         1.12\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MSEs = []\n",
    "Biases = []\n",
    "MAPEs = []\n",
    "MAEs = []\n",
    "RMSEs = []\n",
    "import numpy as np\n",
    "for kk in range (0,3):\n",
    "    np.random.seed(kk)\n",
    "    X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z = Simdata(10000,2,aa,rho)\n",
    "    \n",
    "    res1 = ADeepCI(learner1, adversary).fit(X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, \n",
    "                  X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z, \n",
    "            learner_l2=1e-3, adversary_l2=1e-4, adversary_norm_reg=1e-3,\n",
    "            learner_lr=0.0001, adversary_lr=0.0001, n_epochs=n_epochs, bs=bs, train_learner_every=1, train_adversary_every=1,\n",
    "            ols_weight=0., warm_start=False, logger=None, model_dir='.', device= None, verbose=False)\n",
    "    \n",
    "    model_final = torch.load(os.path.join(res1.model_dir,\"epoch{}\".format(res1.n_epochs - 1)))\n",
    "    \n",
    "    y = model_final(X_2_a_k).cpu().data.numpy()\n",
    "    \n",
    "    if y.ndim == 2:\n",
    "        x = aa(X_2_a_k).cpu().data.numpy()[:, np.newaxis]\n",
    "    else:\n",
    "        x = aa(X_2_a_k).cpu().data.numpy()\n",
    "\n",
    "    RMSE = np.sqrt(np.mean((y - x) ** 2))\n",
    "    RMSEs.append(RMSE)\n",
    "    MAE = np.mean(np.abs(y - x))\n",
    "    MAEs.append(MAE)\n",
    "    MAPE = np.mean(np.abs((y - x) / x)) * 100\n",
    "    MAPEs.append(MAPE)\n",
    "    MSE = np.mean((y - x) ** 2)\n",
    "    MSEs.append(MSE)\n",
    "    Bias = np.mean(y-x)\n",
    "    Biases.append(Bias)\n",
    "y_pred = 2*(X_1_a_j_test.T.squeeze().cpu().data.numpy() + model_final(X_2_a_j_test).squeeze().cpu().data.numpy() > \\\n",
    "           X_1_a_k_test.T.squeeze().cpu().data.numpy() + model_final(X_2_a_k_test).squeeze().cpu().data.numpy())-1\n",
    "y = 1*((y_pred+100)>0) # all ones\n",
    "f1_score(y,y_pred)    \n",
    "print('RMSEs',np.mean(RMSEs))\n",
    "print('MSEs',np.mean(MSEs))\n",
    "print('MAEs',np.mean(MAEs))\n",
    "print('MAPEs',np.mean(MAPEs))\n",
    "print('Biases',np.mean(Biases))\n",
    "print(\"Y shape == X shape: {}\".format(y.shape == x.shape))\n",
    "with open(\"./val.log\", 'a', encoding='utf-8') as f:\n",
    "    f.write(\"--------------------------------\\n\")\n",
    "    f.write(\"DeepCI\\n\")\n",
    "    f.write(\"RMSEs: {}\\n\".format(np.mean(RMSEs)))\n",
    "    f.write(\"MSEs: {}\\n\".format(np.mean(MSEs)))\n",
    "    f.write(\"MAEs: {}\\n\".format(np.mean(MAEs)))\n",
    "    f.write(\"MAPEs: {}\\n\".format(np.mean(MAPEs)))\n",
    "    f.write(\"Biases: {}\\n\".format(np.mean(Biases)))\n",
    "#Fit and summarize OLS model\n",
    "x = sm.add_constant(x, prepend=False)\n",
    "mod = sm.OLS(y,x)\n",
    "res = mod.fit()\n",
    "print(res.summary())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "plt.scatter(X_2_a_k.T.squeeze().cpu().data.numpy(), model_final(X_2_a_k).cpu().data.numpy())\n",
    "plt.savefig(func_run+str(J)+'.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ca49db5-7af3-469e-914f-8551393fb8b5",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76beb017-db9b-4f3e-8fc3-1487df6628ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e84f693-406a-47d0-b3c8-63d5de1aff2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.729059829059829"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = np.concatenate((X_1_a_j.cpu().data.numpy(),X_2_a_j.cpu().data.numpy()),axis = 1)\n",
    "X_2 = np.concatenate((X_1_a_k.cpu().data.numpy(),X_2_a_k.cpu().data.numpy()),axis = 1)\n",
    "y_1 = np.ones(X_1.shape[0])\n",
    "y_2 = np.zeros(X_1.shape[0])\n",
    "\n",
    "X = np.concatenate((X_1,X_2), axis = 0)\n",
    "y = np.concatenate((y_1,y_2), axis = 0)\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "\n",
    "X_a_j_test = np.concatenate((X_1_a_j_test.cpu().data.numpy(),X_2_a_j_test.cpu().data.numpy()),axis = 1)\n",
    "\n",
    "y_pred_clf = 2*clf.predict(X_a_j_test)-1 #1 or -1\n",
    "y_clf = 1*((y_pred_clf+100)>0) # all ones\n",
    "\n",
    "f1_score(y_clf,y_pred_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20d1d8ee-f8bf-462d-b3e0-42b5f31fdf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, precision_score, recall_score, roc_auc_score\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "method = func_run\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def compute_stats(d1_train, d2_train, y_train, d1_test, d2_test, y_test, N, mode):\n",
    "\n",
    "\n",
    "    print(\"J:\",J, \"rho:\",rho, \"method:\",method, \"mode:\",mode)\n",
    "\n",
    "\n",
    "    torch.manual_seed(2)    # reproducible\n",
    "\n",
    "    x1 = torch.tensor(d1_train, dtype=torch.float32)\n",
    "    x2 = torch.tensor(d2_train, dtype=torch.float32)\n",
    "    y  = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "    # torch can only train on Variable, so convert them to Variable\n",
    "    x1, x2, y = Variable(x1), Variable(x2), Variable(y)\n",
    "\n",
    "\n",
    "    if mode == 'PPHI':\n",
    "        net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, 1),\n",
    "            torch.nn.Flatten(0, 1)\n",
    "            )\n",
    "    elif mode == 'polyPPHI':\n",
    "        net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(2, 1),\n",
    "            torch.nn.Flatten(0, 1)\n",
    "            )\n",
    "    else:\n",
    "        net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(1, 300),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(300, 200),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(200, 1),\n",
    "            )\n",
    "\n",
    "\n",
    "    # print(net)  # net architecture\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "    if mode == 'PPHI':\n",
    "        p = torch.tensor([1])\n",
    "        x10 = torch.unsqueeze(x1[:,0],dim=1)\n",
    "        x20 = torch.unsqueeze(x2[:,0],dim=1)\n",
    "        x11 = torch.unsqueeze(x1[:,1:],dim=1).pow(p)\n",
    "        x21 = torch.unsqueeze(x2[:,1:],dim=1).pow(p)\n",
    "    elif mode == 'polyPPHI':\n",
    "        p = torch.tensor([1,2])\n",
    "        x10 = torch.unsqueeze(x1[:,0],dim=1)\n",
    "        x20 = torch.unsqueeze(x2[:,0],dim=1)\n",
    "        x11 = torch.unsqueeze(x1[:,1:],dim=1).pow(p)\n",
    "        x21 = torch.unsqueeze(x2[:,1:],dim=1).pow(p)\n",
    "    else:\n",
    "        p = torch.tensor([1])\n",
    "        x10 = torch.unsqueeze(x1[:,0],dim=1)\n",
    "        x20 = torch.unsqueeze(x2[:,0],dim=1)\n",
    "        x11 = torch.unsqueeze(x1[:,1:],dim=1)\n",
    "        x21 = torch.unsqueeze(x2[:,1:],dim=1)\n",
    "\n",
    "\n",
    "    def deepci_loss(first, second, y):\n",
    "        diff1 = torch.reshape(first - second, (-1,))\n",
    "        diff = diff1*(y>0) + (-diff1)*(y<0)\n",
    "        loss = torch.mean(torch.minimum(torch.zeros(diff.size()),diff)**2)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCH = 100\n",
    "    torch_dataset = Data.TensorDataset(x10, x11, x20, x21, y)\n",
    "\n",
    "    loader = Data.DataLoader(\n",
    "        dataset=torch_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True, num_workers=2,)\n",
    "    iteration = 0\n",
    "\n",
    "    # start training\n",
    "    for epoch in range(EPOCH):\n",
    "        for step, (batch_x10, batch_x11, batch_x20, batch_x21, batch_y) in enumerate(loader): # for each training step\n",
    "\n",
    "            b_x10 = Variable(batch_x10)\n",
    "            b_x11 = Variable(batch_x11)\n",
    "            b_x20 = Variable(batch_x20)\n",
    "            b_x21 = Variable(batch_x21)\n",
    "            b_y = Variable(batch_y)\n",
    "\n",
    "            prediction_1 = b_x10 + net(b_x11)     # input x and predict based on x\n",
    "            prediction_2 = b_x20 + net(b_x21)\n",
    "\n",
    "            loss = deepci_loss(prediction_1, prediction_2, b_y)     # must be (1. nn output, 2. target)\n",
    "            #if iteration%500 == 0:\n",
    "            #    print(loss)\n",
    "            iteration +=1    \n",
    "            optimizer.zero_grad()   # clear gradients for next train\n",
    "            loss.backward()         # backpropagation, compute gradients\n",
    "            optimizer.step()        # apply gradients\n",
    "\n",
    "\n",
    "    x1_test = torch.tensor(d1_test, dtype=torch.float32)\n",
    "    x2_test = torch.tensor(d2_test, dtype=torch.float32)\n",
    "    y       = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    if mode == 'PPHI':\n",
    "        x10_test = torch.unsqueeze(x1_test[:,0],dim=1)\n",
    "        x20_test = torch.unsqueeze(x2_test[:,0],dim=1)\n",
    "        x11_test = torch.unsqueeze(x1_test[:,1:],dim=1).pow(p)\n",
    "        x21_test = torch.unsqueeze(x2_test[:,1:],dim=1).pow(p)\n",
    "    elif mode == 'polyPPHI':\n",
    "        x10_test = torch.unsqueeze(x1_test[:,0],dim=1)\n",
    "        x20_test = torch.unsqueeze(x2_test[:,0],dim=1)\n",
    "        x11_test = torch.unsqueeze(x1_test[:,1:],dim=1).pow(p)\n",
    "        x21_test = torch.unsqueeze(x2_test[:,1:],dim=1).pow(p)\n",
    "    else:\n",
    "        x10_test = torch.unsqueeze(x1_test[:,0],dim=1)\n",
    "        x20_test = torch.unsqueeze(x2_test[:,0],dim=1)\n",
    "        x11_test = torch.unsqueeze(x1_test[:,1:],dim=1)\n",
    "        x21_test = torch.unsqueeze(x2_test[:,1:],dim=1)\n",
    "\n",
    "\n",
    "    if mode == 'NN':\n",
    "        y_pred = 2*(x10_test.flatten() + net(x11_test).data.numpy().flatten() > \\\n",
    "                x20_test.flatten() + net(x21_test).data.numpy().flatten())-1\n",
    "    else:\n",
    "        y_pred = 2*((x10_test + net(x11_test)).flatten() > \\\n",
    "                (x20_test + net(x21_test)).flatten())-1\n",
    "\n",
    "    f1 = f1_score(y.numpy(),y_pred.numpy())\n",
    "    \n",
    "    yy = net(x11_test).cpu().data.numpy()\n",
    "    xx = aa(x1_test[:,1:]).cpu().data.numpy()[:, np.newaxis]\n",
    "\n",
    "    xx = sm.add_constant(xx, prepend=False)\n",
    "    # Fit and summarize OLS model\n",
    "    mod = sm.OLS(yy,xx)\n",
    "    res = mod.fit()\n",
    "    print(res.summary())\n",
    "    print(yy.shape)\n",
    "    print(xx.shape)\n",
    "    \n",
    "    MSE = np.mean((yy - xx) ** 2)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    MAE = np.mean(np.abs(yy - xx))\n",
    "    CE = np.mean(np.abs(yy - xx) / np.abs(xx))\n",
    "    accuracy_score = np.mean((yy - xx) == 0)\n",
    "    Bias = np.mean(yy-xx)\n",
    "        \n",
    "    return f1, RMSE, MAE, CE, accuracy_score, Bias\n",
    "\n",
    "\n",
    "def simulateData(N, J, K, func, rho, sim):\n",
    "    np.random.seed(sim)\n",
    "    D = np.random.uniform(-1,1,(N,J + 1,K))\n",
    "    x1 = np.array([])\n",
    "    x2 = np.array([])\n",
    "    y  = np.array([])\n",
    "    for n in range(N):\n",
    "        err = np.random.normal(0,0.5) # epsilon_m\n",
    "        D[n,1:,1] = 5*D[n,1:,1] + rho*err\n",
    "        D[n,1:,0] = D[n,1:,0] \n",
    "        choice = np.argmax(D[n,:,0] + 2*func(D[n,:,1:]) + np.random.normal(0,3,(1,J + 1)) + err) # x_0+f(x_1) for each product\n",
    "        if choice == 0:\n",
    "            continue\n",
    "        for j in range(1, J+1):\n",
    "            if j == choice:\n",
    "                continue\n",
    "            else:\n",
    "                #print(D[n,choice,:])\n",
    "                if x1.size == 0:\n",
    "                    x1 = D[n,choice,:]\n",
    "                    x2 = D[n,j,:]\n",
    "                    y  = np.array([1])\n",
    "                else:    \n",
    "                    x1 = np.c_[x1, D[n,choice,:]]\n",
    "                    x2 = np.c_[x2, D[n,j,:]]\n",
    "                    y  = np.c_[y,np.array([1])]\n",
    "    return x1.T, x2.T, y.T\n",
    "\n",
    "\n",
    "print(method)\n",
    "\n",
    "\n",
    "def runConfig(J, rho, method, mode):\n",
    "    N = 2000\n",
    "    K = 2\n",
    "    a, b = get_function(method)\n",
    "    MSEs = []\n",
    "    f1 = []\n",
    "    RMSE = []\n",
    "    MAE = []\n",
    "    CE = []\n",
    "    accuracy_score = []\n",
    "    for i in range(1,2): \n",
    "        d1_train, d2_train, y_train = simulateData(N, J, K, a, rho, i)\n",
    "        d1_test,  d2_test,  y_test  = simulateData(N, J, K, a, rho, i+1)\n",
    "        f1, RMSE, MAE, CE, accuracy_score, Bias = compute_stats(d1_train, d2_train, y_train, d1_test, d2_test, y_test, method, mode)\n",
    "        # RMSEs.append(RMSE)\n",
    "        MSEs.append(MSE)\n",
    "        Biases.append(Bias)\n",
    "\n",
    "    return np.mean(MSEs), np.mean(Biases), f1, RMSE, MAE, CE, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8e46101-ac6b-423f-bf40-20b9d81f6f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function(func_str):\n",
    "    if func_str == \"abs\":\n",
    "        return (lambda x: (-1+0.4*np.abs(x@np.ones((1,1)))).flatten(), \n",
    "                lambda x: (-1+0.4*torch.abs(x@np.ones((1,1)))).flatten())\n",
    "    elif func_str == \"log\":\n",
    "        return (lambda x: 2*np.log(np.abs(x@np.ones((1,1)))).flatten(), \n",
    "                lambda x: 2*torch.log(torch.abs(x@np.ones((1,1)))).flatten())\n",
    "    elif func_str == \"sin\":\n",
    "        return (lambda x: np.sin(x@np.ones((1,1))).flatten(), \n",
    "                lambda x: torch.sin(x@np.ones((1,1))).flatten())\n",
    "    else:\n",
    "        return (lambda x: np.sign(np.abs(np.abs(x@np.ones((1,1)))-5)-2).flatten(), \n",
    "                lambda x: torch.sign(torch.abs(torch.abs(x@np.ones((1,1)))-5)-2).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1260198d-bb5e-4dc2-b88f-b0624bafedc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 10 rho: 0.2 method: step mode: polyPPHI\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.621\n",
      "Model:                            OLS   Adj. R-squared:                  0.621\n",
      "Method:                 Least Squares   F-statistic:                     9701.\n",
      "Date:                Fri, 26 May 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:25:29   Log-Likelihood:                 720.16\n",
      "No. Observations:                5920   AIC:                            -1436.\n",
      "Df Residuals:                    5918   BIC:                            -1423.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.4600      0.005     98.492      0.000       0.451       0.469\n",
      "const         -0.4751      0.005   -101.727      0.000      -0.484      -0.466\n",
      "==============================================================================\n",
      "Omnibus:                      411.152   Durbin-Watson:                   0.516\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              499.661\n",
      "Skew:                          -0.703   Prob(JB):                    3.16e-109\n",
      "Kurtosis:                       3.218   Cond. No.                         3.02\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(5920, 1)\n",
      "(5920, 2)\n",
      "MSE:  0.19256923107503648 Bias:  -0.36925408357980793 f1:  0.8113643208513202 RMSE:  1.0768438719694113 \n",
      " MAE:  1.0261031634753217 CE:  1.0261031634753217 accuracy_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "mode = 'polyPPHI'\n",
    "\n",
    "MSE, Bias, f1, RMSE, MAE, CE, accuracy_score = runConfig(5, 0.5, method, mode)\n",
    "print('MSE: ', MSE, 'Bias: ', Bias, 'f1: ', f1, 'RMSE: ', RMSE, '\\n','MAE: ', MAE, 'CE: ', CE, 'accuracy_score: ', accuracy_score)\n",
    "with open(\"./val.log\", 'a', encoding='utf-8') as f:\n",
    "    f.write(\"--------------------------------\\n\")\n",
    "    f.write(\"polyPPHI\\n\")\n",
    "    f.write(\"RMSEs: {}\\n\".format(RMSE))\n",
    "    f.write(\"MSEs: {}\\n\".format(MSE))\n",
    "    f.write(\"MAEs: {}\\n\".format(MAE))\n",
    "    f.write(\"MAPEs: {}\\n\".format(CE *100))\n",
    "    f.write(\"Biases: {}\\n\".format(Bias))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b3975f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J: 10 rho: 0.2 method: step mode: PPHI\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     12.36\n",
      "Date:                Fri, 26 May 2023   Prob (F-statistic):           0.000441\n",
      "Time:                        14:28:09   Log-Likelihood:                 8837.2\n",
      "No. Observations:                5920   AIC:                        -1.767e+04\n",
      "Df Residuals:                    5918   BIC:                        -1.766e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0042      0.001      3.516      0.000       0.002       0.006\n",
      "const         -0.2418      0.001   -204.027      0.000      -0.244      -0.240\n",
      "==============================================================================\n",
      "Omnibus:                      255.296   Durbin-Watson:                   0.496\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              119.353\n",
      "Skew:                           0.129   Prob(JB):                     1.21e-26\n",
      "Kurtosis:                       2.354   Cond. No.                         3.02\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "(5920, 1)\n",
      "(5920, 2)\n",
      "MSE:  0.19256923107503648 Bias:  -0.523373667006355 f1:  0.7340960119747674 RMSE:  1.2199629534400112 \n",
      " MAE:  1.2142316936943176 CE:  1.2142316936943176 accuracy_score:  0.0\n"
     ]
    }
   ],
   "source": [
    "mode = 'PPHI'\n",
    "\n",
    "MSE, Bias, f1, RMSE, MAE, CE, accuracy_score = runConfig(5, 0.5, method, mode)\n",
    "print('MSE: ', MSE, 'Bias: ', Bias, 'f1: ', f1, 'RMSE: ', RMSE,'\\n', 'MAE: ', MAE, 'CE: ', CE, 'accuracy_score: ', accuracy_score)\n",
    "with open(\"./val.log\", 'a', encoding='utf-8') as f:\n",
    "    f.write(\"--------------------------------\\n\")\n",
    "    f.write(\"PPHI\\n\")\n",
    "    f.write(\"RMSEs: {}\\n\".format(RMSE))\n",
    "    f.write(\"MSEs: {}\\n\".format(MSE))\n",
    "    f.write(\"MAEs: {}\\n\".format(MAE))\n",
    "    f.write(\"MAPEs: {}\\n\".format(CE *100))\n",
    "    f.write(\"Biases: {}\\n\".format(Bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0e7e91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "美食展示\n"
     ]
    }
   ],
   "source": [
    "unicode_str = \"\\\\u7f8e\\\\u98df\\\\u5c55\\\\u793a\"\n",
    "decoded_str = unicode_str.encode().decode('unicode_escape')\n",
    "print(decoded_str)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4bbbb1caf6068806cf1f83a6fd7c1be9d55c9e1f598b89b3e470bcb422c3095"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
