{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d77d2b9-1d2b-4d84-8c0e-2b51d3a546e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lqs\\Downloads\\DeepCI\n"
     ]
    }
   ],
   "source": [
    "seedNum = 888\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "tf.random.set_seed(seedNum)\n",
    "np.random.seed(seedNum)\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import sys, os\n",
    "print(os.getcwd())\n",
    "# os.chdir('/media/lqs/李秋水的移动硬盘1/DeepCI')\n",
    "os.chdir('c:/Users/lqs/Downloads/DeepCI')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "torch.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "# ! pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf8b10a-8dd2-42d5-9c51-7a12f027e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train/255# shape (60000, 28, 28)\n",
    "X_test  = X_test/255# shape (10000, 28, 28)\n",
    "(example_X_train,example_y_train) = (X_train[:2000], y_train[:2000])\n",
    "(example_X_test,example_y_test) = (X_test[:2000], y_test[:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab882a9-0c11-4b14-8b59-c6e96ab30e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = y_train\n",
    "b = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "200e8919-53b0-42e5-bdac-f85441a5b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_run = \"none\"\n",
    "n_epochs = 200\n",
    "bs = 200\n",
    "args={}\n",
    "kwargs={}\n",
    "args['batch_size']=100\n",
    "args['test_batch_size']=200\n",
    "args['epochs']=50  #The number of Epochs is the number of times you go through the full dataset. \n",
    "args['lr']=0.0002 #Learning rate is how fast it will decend. \n",
    "args['momentum']=0.5 #SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
    "\n",
    "args['seed']=1 #random seed\n",
    "args['log_interval']=600\n",
    "args['cuda']= True #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d331d3a7-f7c5-4fae-8334-4120b9635831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function(func_str):\n",
    "    if func_str == \"abs\":\n",
    "        return (lambda x: (-1+0.4*np.abs(x)).flatten(), \n",
    "                lambda x: (-1+0.4*torch.abs(x)).flatten())\n",
    "    elif func_str == \"log\":\n",
    "        return (lambda x: 2*np.log(np.abs(x)).flatten(), \n",
    "                lambda x: 2*torch.log(torch.abs(x)).flatten())\n",
    "    elif func_str == \"sin\":\n",
    "        return (lambda x: (0.5+0.5*np.sin(x)).flatten(), \n",
    "                lambda x: (0.5+0.5*torch.sin(x)).flatten())\n",
    "    elif func_str == \"none\":\n",
    "        return (lambda x: 0.2*x.flatten(), \n",
    "                lambda x: 0.2*torch.Tensor(x).flatten())\n",
    "    else:\n",
    "        return (lambda x: np.sign(np.abs(np.abs(x)-5)-2).flatten(), \n",
    "                lambda x: torch.sign(torch.abs(torch.abs(x)-5)-2).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb4ee77-a552-4026-9dac-14abf4b70b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simdata(NUM_I,seed,func,rho): #a = y_train/test, b = X_train/test\n",
    "    \n",
    "    np.random.seed(seed)    \n",
    "    X_1_a_j = [] \n",
    "    X_2_a_j = [] \n",
    "    X_1_a_k = [] \n",
    "    X_2_a_k = [] \n",
    "    X_1_b_j = [] \n",
    "    X_2_b_j = [] \n",
    "    X_1_b_k = [] \n",
    "    X_2_b_k = []\n",
    "    Z       = []\n",
    "    \n",
    "\n",
    "    X_2_a_j_t = [] \n",
    "    X_2_a_k_t = [] \n",
    "    X_2_b_j_t = [] \n",
    "    X_2_b_k_t = []\n",
    "\n",
    "    for i in tqdm(range(0,NUM_I)):\n",
    "        J = np.random.randint(4,10) # number of choice\n",
    "              \n",
    "        \n",
    "        samplea = np.array(random.sample(list(np.arange(a.shape[0])),J)) # a list of index\n",
    "        samplea = np.expand_dims(samplea, axis=1)\n",
    "        ej = np.concatenate([a[i] for i in samplea],axis = None) # a list of number on images\n",
    "        ej = [i for i in ej.tolist()]\n",
    "        ej = np.float_(ej)\n",
    "\n",
    "        X_1_a = np.random.uniform(-1,1,J) #customer a\n",
    "        X_2_a = ej\n",
    "        X_2_a_pic = [torch.Tensor(b[i]) for i in samplea]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        sampleb = np.array(random.sample(list(np.arange(a.shape[0])),J)) # a list of index\n",
    "        sampleb = np.expand_dims(sampleb, axis=1)\n",
    "        ej = np.concatenate([a[i] for i in sampleb],axis = None) # a list of number on images\n",
    "        ej = [i for i in ej.tolist()]\n",
    "        ej = np.float_(ej)\n",
    "        \n",
    "        X_1_b = np.random.uniform(-1,1,J) #customer b\n",
    "        X_2_b = ej\n",
    "        X_2_b_pic = [torch.Tensor(b[i]) for i in sampleb]\n",
    "        \n",
    "        \n",
    "        \n",
    "        xi  = np.random.normal(0,0.5,J)    # same across all customers\n",
    "        \n",
    "        # X_2_a = X_2_a + rho*xi  #customer a endogeneity remove for now\n",
    "        # X_2_b = X_2_b + rho*xi  #customer b endogeneity remove for now\n",
    "        \n",
    "        u_a   = X_1_a + 2*func(X_2_a) + xi + np.random.normal(0,3,J) # \\epsilon_{a} # 3 for score\n",
    "        u_b   = X_1_b + 2*func(X_2_b) + xi + np.random.normal(0,3,J) # \\epsilon_{b}\n",
    "        \n",
    "        choice_j = np.argmax(u_a) # return the index of product in the sample that customer a chose, we assume customer a as choose j\n",
    "        choice_k = np.argmax(u_b) # return the index of product in the sample that customer b chose, we assume customer b as choose k\n",
    "               \n",
    "        if choice_j == choice_k:\n",
    "            continue\n",
    "        else:  \n",
    "\n",
    "            X_1_a_j.append(X_1_a[choice_j])\n",
    "            X_2_a_j.append(X_2_a_pic[choice_j])\n",
    "            X_1_a_k.append(X_1_a[choice_k])\n",
    "            X_2_a_k.append(X_2_a_pic[choice_k])\n",
    "            \n",
    "            X_1_b_j.append(X_1_b[choice_j]) \n",
    "            X_2_b_j.append(X_2_b_pic[choice_j]) \n",
    "            X_1_b_k.append(X_1_b[choice_k]) \n",
    "            X_2_b_k.append(X_2_b_pic[choice_k])\n",
    "            \n",
    "            \n",
    "            \n",
    "            X_2_a_j_t.append(X_2_a[choice_j])\n",
    "            X_2_a_k_t.append(X_2_a[choice_k])             \n",
    "            X_2_b_j_t.append(X_2_b[choice_j]) \n",
    "            X_2_b_k_t.append(X_2_b[choice_k])\n",
    "            #Z.append(np.array([X_1_a[choice_j], X_2_a[choice_j], X_1_a[choice_k], X_2_a[choice_k],X_1_b[choice_j], X_2_b[choice_j], X_1_b[choice_k], X_2_b[choice_k]]))\n",
    "            Z.append(np.array([X_1_a[choice_j],X_1_a[choice_k],X_1_b[choice_j],X_1_b[choice_k]]))\n",
    "            \n",
    "    X_2_a_j = torch.cat(X_2_a_j, out=torch.Tensor(len(X_2_a_j), 28, 28))\n",
    "    X_2_a_k = torch.cat(X_2_a_k, out=torch.Tensor(len(X_2_a_k), 28, 28))\n",
    "    X_2_b_j = torch.cat(X_2_b_j, out=torch.Tensor(len(X_2_b_j), 28, 28))\n",
    "    X_2_b_k = torch.cat(X_2_b_k, out=torch.Tensor(len(X_2_b_k), 28, 28))\n",
    "    \n",
    "            \n",
    "    print(\"simdata:X_2_a_k:\",X_2_a_k.shape)\n",
    "    return torch.Tensor(X_1_a_j).reshape((-1,1)).double(), X_2_a_j.unsqueeze(1), \\\n",
    "    torch.Tensor(X_1_a_k).reshape((-1,1)).double(), X_2_a_k.unsqueeze(1), torch.Tensor(X_1_b_j).reshape((-1,1)).double(), \\\n",
    "    X_2_b_j.unsqueeze(1), torch.Tensor(X_1_b_k).reshape((-1,1)).double(), X_2_b_k.unsqueeze(1), \\\n",
    "    torch.tensor(Z, dtype=torch.float64),\\\n",
    "    torch.Tensor(X_2_a_j_t).reshape((-1,1)).double(), torch.Tensor(X_2_a_k_t).reshape((-1,1)).double(),\\\n",
    "    torch.Tensor(X_2_b_j_t).reshape((-1,1)).double(), torch.Tensor(X_2_b_k_t).reshape((-1,1)).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ad8027-3000-4929-b8d3-47a42661db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa,bb = get_function(func_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38b07e4-f0c0-4b72-96d6-925250d5953a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:15<00:00, 316.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simdata:X_2_a_k: torch.Size([4089, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z,  X_2_a_j_t, X_2_a_k_t,  X_2_b_j_t,  X_2_b_k_t= Simdata(5000,2,aa,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af377986-f660-44fb-bebf-196143c5df74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4089, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image = X_2_a_k[6]\n",
    "# plot the sample\n",
    "fig = plt.figure\n",
    "plt.imshow(image.squeeze(0), cmap='gray')\n",
    "plt.show()\n",
    "print(X_2_a_k.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95b4d8d7-1c6f-4b3f-bb7d-cfcc9124013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\lqs\\\\Downloads\\\\DeepCI', 'c:\\\\Python311\\\\python311.zip', 'c:\\\\Python311\\\\Lib', 'c:\\\\Python311\\\\DLLs', '', 'C:\\\\Users\\\\lqs\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\lqs\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\lqs\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\lqs\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Python311', 'c:\\\\Python311\\\\Lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path\n",
    "print(sys.path)\n",
    "sys.path.append('/notebooks/AdversarialGMM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "884b4136-77ea-4c22-8e12-857fe1d8954a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "device = torch.cuda.current_device() if torch.cuda.is_available() else None\n",
    "print(torch.cuda.is_available())\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aab8430-e3fa-4560-a3da-8e0178dbdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 256\n",
    "n_hidden = 300\n",
    "n_instruments = 1\n",
    "dropout_p = 0.1\n",
    "\n",
    "net_learner_supervised = torch.nn.Sequential(\n",
    "            torch.nn.Linear(784, k),\n",
    "            torch.nn.BatchNorm1d(k),\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            torch.nn.Dropout(p=dropout_p),\n",
    "            torch.nn.Linear(k, 256),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Linear(256, 10),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "            )# input shape (batch, 784), output shape (batch, 1)\n",
    "\n",
    "net_adversary = torch.nn.Sequential(\n",
    "            torch.nn.Linear(784, k),# 48 is the number of features\n",
    "            torch.nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(p=0.1),                        \n",
    "            torch.nn.Linear(k, 256), #200\n",
    "            torch.nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.1),                        \n",
    "            torch.nn.Linear(256, 784),\n",
    "            torch.nn.Tanh()\n",
    "            )# input shape (batch, 1, 28, 28), output shape (batch, 1, 28, 28)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af8e7340-744a-419f-ba28-ed4aa0ada630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       \n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=True, **kwargs)\n",
    "\n",
    "import torchvision.transforms as T\n",
    "transform = T.Resize((32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af180df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(100, 256),  # 用线性变换将输入映射到256维\n",
    "            nn.ReLU(True),  # relu激活\n",
    "            nn.Linear(256, 256),  # 线性变换\n",
    "            nn.ReLU(True),  # relu激活\n",
    "            nn.Linear(256, 784),  # 线性变换\n",
    "            nn.Tanh()  # Tanh激活使得生成数据分布在【-1,1】之间，因为输入的真实数据的经过transforms之后也是这个分布\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.gen(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "988ed727-a48d-4d1e-babb-0a3bf9ce94a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Net_X"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net_X(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_X, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return x.squeeze()\n",
    "\n",
    "Net_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7870d0d-2397-4fbf-811b-ffc4d4b07475",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.Tensor(X_train[:100]).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5026298d-d7a5-4dda-8cab-be86cd62005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = net_learner_supervised\n",
    "\n",
    "adversary = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9663e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if args['cuda']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "        #Variables in Pytorch are differenciable. \n",
    "        #data = transform(data)\n",
    "        #data = torch.concat([data,data,data],axis=1)\n",
    "        #\n",
    "        data = data.float()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #This will zero out the gradients for this batch. \n",
    "        optimizer.zero_grad()\n",
    "        data = data.view(-1, 784)\n",
    "        output = model(data)\n",
    "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
    "        loss = F.nll_loss(output, target)\n",
    "        #dloss/dx for every Variable \n",
    "        loss.backward()\n",
    "        #to do a one-step update on our parameter.\n",
    "        optimizer.step()\n",
    "        #Print out the loss periodically. \n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss))\n",
    "\n",
    "def test(model):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if args['cuda']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        data = torch.flatten(data, start_dim=1)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data.item()\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    test_loss /= len(test_loader)\n",
    "    print(\"test_loss: \", test_loss)\n",
    "    print(\"Accuracy: \", 100. * correct / len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cbc2400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net_X().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# for epoch in range(1, 50):\n",
    "#     train(epoch)\n",
    "#     test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd6c472a-034d-487b-b8c7-1ae64e709cb1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ADeepCI\n",
      "BaseSupLossADeepCI: Training learner and adversary\n",
      "shape of x_2_a_j_batch torch.Size([200, 1, 28, 28])\n",
      "Type of pred_a_k <class 'torch.Tensor'>\n",
      "Type of X_2_a_k_t <class 'torch.Tensor'>\n",
      "shape(pred_a_k) torch.Size([200, 1])\n",
      "shape(X_2_a_k_t) torch.Size([200, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39madeepci\u001b[39;00m \u001b[39mimport\u001b[39;00m ADeepCI\n\u001b[0;32m      2\u001b[0m CUDA_LAUNCH_BLOCKING\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m----> 3\u001b[0m res \u001b[39m=\u001b[39m ADeepCI(learner, adversary)\u001b[39m.\u001b[39;49mfit(X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, \n\u001b[0;32m      4\u001b[0m                   X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z, X_2_a_j_t,X_2_a_k_t,X_2_b_j_t,X_2_b_k_t,\n\u001b[0;32m      5\u001b[0m                   learner_l2\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m, adversary_l2\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m, adversary_norm_reg\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m                   learner_lr\u001b[39m=\u001b[39;49m\u001b[39m0.00001\u001b[39;49m, adversary_lr\u001b[39m=\u001b[39;49m\u001b[39m0.00002\u001b[39;49m, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, bs\u001b[39m=\u001b[39;49mbs, train_learner_every\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, train_adversary_every\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m      7\u001b[0m                   ols_weight\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, warm_start\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, logger\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, model_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m'\u001b[39;49m, device \u001b[39m=\u001b[39;49m device, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\lqs\\Downloads\\DeepCI\\model\\adeepci.py:218\u001b[0m, in \u001b[0;36m_BaseSupLossADeepCI.fit\u001b[1;34m(self, X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z, X_2_a_j_t, X_2_a_k_t, X_2_b_j_t, X_2_b_k_t, learner_l2, adversary_l2, adversary_norm_reg, learner_lr, adversary_lr, n_epochs, bs, train_learner_every, train_adversary_every, ols_weight, warm_start, logger, model_dir, device, verbose)\u001b[0m\n\u001b[0;32m    215\u001b[0m D_loss \u001b[39m=\u001b[39m d_loss\n\u001b[0;32m    217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizerD\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> 218\u001b[0m D_loss\u001b[39m.\u001b[39;49mbackward(retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    219\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizerD\u001b[39m.\u001b[39mstep()\n\u001b[0;32m    220\u001b[0m all_D_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m D_loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "from model.adeepci import ADeepCI\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "res = ADeepCI(learner, adversary).fit(X_1_a_j, X_2_a_j, X_1_a_k, X_2_a_k, \n",
    "                  X_1_b_j, X_2_b_j, X_1_b_k, X_2_b_k, Z, X_2_a_j_t,X_2_a_k_t,X_2_b_j_t,X_2_b_k_t,\n",
    "                  learner_l2=1e-4, adversary_l2=1e-4, adversary_norm_reg=1e-4,\n",
    "                  learner_lr=0.00001, adversary_lr=0.00002, n_epochs=50, bs=bs, train_learner_every=1, train_adversary_every=1,\n",
    "                  ols_weight=0.1, warm_start=True, logger=None, model_dir='.', device = device, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41e0df7-e0bc-4bad-95dc-0a80d9bdf053",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_temp = learner #torch.load(os.path.join(res.model_dir,\"epoch{}\".format(res.n_epochs - 1)))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "X_2_a_k = torch.flatten(X_2_a_k, start_dim=1)\n",
    "print(\"shape of X_2_a_k: \", X_2_a_k.shape)\n",
    "test(model_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ec110-5f6f-4121-9415-840af5e03a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_2_a_k_t.T.squeeze().cuda().data.numpy(), aa(X_2_a_k_t).cuda().data.numpy())# plot the true function\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ba91b-99bd-4608-a527-12000628b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = learner(X_2_a_k).cpu().data.numpy()\n",
    "x = aa(X_2_a_k_t).cpu().data.numpy()\n",
    "\n",
    "print(np.mean((y - x) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c6707-ef9d-49a1-a653-90c9cfd0fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sm.add_constant(x, prepend=False)\n",
    "\n",
    "# Fit and summarize OLS model\n",
    "mod = sm.OLS(y,x)\n",
    "\n",
    "res = mod.fit()\n",
    "\n",
    "print(res.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "34752fb930ccda7383b9ea105c0ef5936eec2182d44ee5b0b4b02e4beea6e55f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
